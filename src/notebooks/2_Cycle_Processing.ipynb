{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de152bce-3aae-4e74-b337-ff06e0345601",
   "metadata": {},
   "source": [
    "# Part 2: Batch Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9b613-22fc-40c7-a4a3-e5f0b1cb9f73",
   "metadata": {},
   "source": [
    "In the following notebook you will use the parameters found in A_Evaluation&Testing.ipynb to correct and stitch entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20908051-79d7-4e17-8725-587ca5084c2b",
   "metadata": {},
   "source": [
    "## 1. Import packages. \n",
    "*This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b61c7f-445a-466f-a3d3-dfefa0d45258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import os as os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import KCorrect\n",
    "from Kstitch.stitching import stitch_images\n",
    "from glob import glob\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection, imsave\n",
    "import stackview\n",
    "import numpy as np\n",
    "from itertools import chain, repeat\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import imagej, scyjava\n",
    "import logging\n",
    "import pyopencl as cl\n",
    "import warnings\n",
    "import platform\n",
    "os_system = platform.system()\n",
    "current_dateTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2ab6-e1f7-45b0-96c2-a2a691807caf",
   "metadata": {},
   "source": [
    "## 2. Define directory paths. \n",
    "*This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b6a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:\\\\Users\\\\smith6jt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2736065-d891-45e8-a56e-8190ce6028e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_raw.\n",
      "Stitching folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_BaSiC_Stitched.\n",
      "Meta folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_meta.\n"
     ]
    }
   ],
   "source": [
    "image_dir = os.path.join(base_dir, 'KINTSUGI', 'data', '1904_CC2B_raw')\n",
    "stitch_dir = image_dir.replace(\"_raw\", \"_BaSiC_Stitched\")\n",
    "meta_dir = stitch_dir.replace(\"_BaSiC_Stitched\", \"_meta\")\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Image folder is {image_dir}.\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986ebe1-7f2e-4591-b8df-a6dbd6a21eeb",
   "metadata": {},
   "source": [
    "## 3. Stitching and Illumination Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713805",
   "metadata": {},
   "source": [
    "### 3.1 Stitching Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d7e45",
   "metadata": {},
   "source": [
    "- The following cell defines the function that is called from the apply_basic function to stitch the corrected tiles.  \n",
    "- It creates a file with the stitching positions calculated from the middle z-plane images of the first channel.\n",
    "- The file is then used to stitch the rest of the images for all channels in the cycle. BECAUSE OF THIS, YOU MUST HAVE RUN THE FIRST CHANNEL OF A CYCLE TO STITCH THE OTHER CHANNELS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8598a778-b89c-4872-a1c6-a03819c37d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(images_transformed, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu):\n",
    "    \n",
    "    z = str(zplanes)\n",
    "    ch = str(channels)\n",
    "    pkl_dest = os.path.join(dest, \"result_df.pkl\")\n",
    "    \n",
    "    if zplanes == zplanes_n//2 and channels == 1:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(pkl_dest):\n",
    "            result_df = pd.read_pickle(pkl_dest)\n",
    "        else:\n",
    "            result_df, _ = stitch_images(images_transformed, rows, cols, initial_ncc_threshold=0.0, overlap_percentage=overlap_percentage, pou=pou, use_gpu=use_gpu)\n",
    "            result_df.to_pickle(pkl_dest)\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(os.path.join(dest_1, \"result_df.pkl\")):\n",
    "            result_df = pd.read_pickle(os.path.join(dest_1, \"result_df.pkl\"))\n",
    "\n",
    "        else:\n",
    "            print(\"Run registration channel to produce a stitching model.\")\n",
    "\n",
    "    result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "    result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "    \n",
    "    size_y = images_transformed.shape[1]\n",
    "    size_x = images_transformed.shape[2]\n",
    "    \n",
    "    stitched_image_size = (\n",
    "        result_df[\"y_pos2\"].max() + size_y,\n",
    "        result_df[\"x_pos2\"].max() + size_x,\n",
    "    )\n",
    "    stitched_image = np.zeros_like(images_transformed, shape=stitched_image_size)\n",
    "    \n",
    "    for i, row in result_df.iterrows():\n",
    "        stitched_image[\n",
    "            row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "            row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "        ] = images_transformed[i]\n",
    "\n",
    "    result_image_file_path = os.path.join(dest,f\"{z.zfill(2)}.tif\") \n",
    "    imsave(result_image_file_path, stitched_image, check_contrast=False)\n",
    "    \n",
    "    print(f\"Saved to {result_image_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ff441",
   "metadata": {},
   "source": [
    "### 3.2 Illumination Correction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4328b6a-0eb6-4499-9e7e-27f040a60a14",
   "metadata": {},
   "source": [
    "- The following cell contains the function that will apply the illumination correction to your data.  \n",
    "- Change the five variables below according to tests using the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725a6802-1694-4881-85cf-21821ba0439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu):\n",
    "\n",
    "    if_darkfield = True\n",
    "    max_iterations = 500\n",
    "    optimization_tolerance = 1e-6\n",
    "    max_reweight_iterations = 25\n",
    "    reweight_tolerance = 1.0e-3\n",
    "\n",
    "    filename_pattern = f'1_000??_Z0{str(zplanes).zfill(2)}_CH{str(channels)}.tif'\n",
    "    \n",
    "    dest = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", f\"CH{str(channels)}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    dest_1 = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", \"CH1\")\n",
    "    \n",
    "    im_raw = sorted(glob(os.path.join(image_dir, f'cyc{str(cycles).zfill(3)}', filename_pattern)), key=alphanumeric_key)\n",
    "    im = imread_collection(im_raw)\n",
    "    im_array_init = np.asarray(im)\n",
    "    dtype_max = np.iinfo(im_array_init.dtype).max\n",
    "    im_array = im_array_init.astype(np.float64) / dtype_max\n",
    "\n",
    "    if not np.all(np.isfinite(im_array)):\n",
    "        raise ValueError(\"Input array contains inf or nan values\")\n",
    "    if np.any(im_array < 0):\n",
    "        raise ValueError(\"Input array contains negative values\")\n",
    "\n",
    "    print(f\"Start Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "    flatfield, darkfield = KCorrect.KCorrect(im_array, if_darkfield = if_darkfield, max_iterations = max_iterations, optimization_tolerance = optimization_tolerance,  max_reweight_iterations = max_reweight_iterations, reweight_tolerance = reweight_tolerance)\n",
    "    \n",
    "    if np.any(np.isnan(flatfield)) or np.any(np.isnan(darkfield)):\n",
    "        raise ValueError(\"Invalid flatfield or darkfield correction\")\n",
    "    if np.any(flatfield == 0):\n",
    "        warnings.warn(\"Flatfield contains zero values which may cause division issues\")\n",
    "    \n",
    "    corrected = np.zeros_like(im_array, dtype=np.float64)\n",
    "    for i in range(len(im_array)):\n",
    "        corrected[i] = ((im_array[i] - darkfield) / flatfield)\n",
    "        corrected[i] = np.clip(corrected[i], 0, 1)\n",
    "        \n",
    "    KCorrect.validate_correction(im_array_init, corrected)\n",
    "    corrected = (corrected * dtype_max).astype(np.uint16)                                       \n",
    "    stitch(corrected, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627091e-c1aa-4a7e-b6ef-a570bf28932d",
   "metadata": {},
   "source": [
    "### 3.3 Running Multiple Cycle/Channel Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18604-75ad-4533-a9f9-b5dbe9785475",
   "metadata": {},
   "source": [
    "- This cell runs the above two functions for all the images you define with start_cycle, end_cycle, start_channel, and end_channel.  \n",
    "- Enter values for n, m, pou (determined from the first notebook), zplanes_n (number of zplanes), and overlap_percentage.  \n",
    "- Enter the number of workers for the multithreading (usually determined by dataset size, available memory, and number of cores).  See https://docs.python.org/3/library/concurrent.futures.html\n",
    "- To run just one cycle or channel, simply enter the same number for both start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9  # Number of rows (height)\n",
    "m = 7  # Number of columns (width)\n",
    "start_cycle = 1\n",
    "end_cycle = 13\n",
    "start_channel = 1\n",
    "end_channel = 4\n",
    "pou = 13\n",
    "zplanes_n = 17\n",
    "overlap_percentage = 0.30\n",
    "workers = zplanes_n-1\n",
    "use_gpu = True\n",
    "\n",
    "# Row coordinates: each row index is repeated m times\n",
    "rows = list(chain.from_iterable(repeat(row, m) for row in range(n)))\n",
    "# Column coordinates: snake pattern for each row, going back and forth from top left going right\n",
    "cols = list(chain.from_iterable(range(m) if row % 2 == 0 else range(m - 1, -1, -1) for row in range(n)))\n",
    "\n",
    "image_dir_list = [image_dir] * (zplanes_n-1)\n",
    "stitch_dir_list = [stitch_dir] * (zplanes_n-1)\n",
    "zplanes_list =[zplanes_n] * (zplanes_n-1)\n",
    "pou_list = [pou] * (zplanes_n-1)\n",
    "rows_list = [rows] * (zplanes_n-1)\n",
    "cols_list = [cols] * (zplanes_n-1)\n",
    "overlap_percentage_list = [overlap_percentage] * (zplanes_n-1)\n",
    "use_gpu_list = [use_gpu] * (zplanes_n-1)\n",
    "\n",
    "\n",
    "total_operations = (end_cycle - start_cycle + 1) * (end_channel - start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(start_cycle, end_cycle+1):\n",
    "        for j in range(start_channel, end_channel+1):\n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            cycles = i\n",
    "            zplanes = zplanes_n//2 \n",
    "            channels = display_jpeg\n",
    "            apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu)\n",
    "            \n",
    "            if __name__ ==  '__main__':\n",
    "                with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "                    cycles = [i] * (zplanes_n-1) \n",
    "                    zplanes =  list(range(1, zplanes_n//2))+list(range((zplanes_n//2)+1, zplanes_n+1)) \n",
    "                    channels = [j] * (zplanes_n-1)\n",
    "                    executor.map(apply_KCorrect, image_dir_list, stitch_dir_list, zplanes, cycles, channels, zplanes_list, pou_list, rows_list, cols_list, overlap_percentage_list, use_gpu_list) \n",
    "\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3723d-e254-4bd1-bb5b-639f35e66dcc",
   "metadata": {},
   "source": [
    "## 4. Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fefaab-7c4a-4624-b85f-f26644b967f6",
   "metadata": {},
   "source": [
    "- See the first notebook for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2ca0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(command):\n",
    "    \n",
    "    process = subprocess.Popen(command, \n",
    "                                stdout=subprocess.PIPE, \n",
    "                                stderr=subprocess.STDOUT, \n",
    "                                shell=True, \n",
    "                                bufsize=1,\n",
    "                                universal_newlines=True, \n",
    "                                text=True)\n",
    "    \n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output, end='') \n",
    "\n",
    "    rc = process.poll()\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a9e249-9b51-4bde-b711-0a40ddcd8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decon(base_dir, stitch_dir, dec_cycle, dec_channel):\n",
    "\n",
    "    # pixel size in xy dimension (nanometers)\n",
    "    xy_vox = 377\n",
    "    # pixel size in z dimension (nanometers)\n",
    "    z_vox = 1500\n",
    "    # Number of iterations of Lucy-Richardson algo before stopping unless stop_crit is met first\n",
    "    iterations = 25\n",
    "    # Microscope objective numerical aperture\n",
    "    mic_NA = 0.75\n",
    "    # Refractive index of tissue being imaged\n",
    "    tissue_RI = 1.44\n",
    "    # Opening size in millimeters of objective aperture\n",
    "    slit_aper = 6.5\n",
    "    # Focal length in millimeters of objective\n",
    "    f_cyl = 1\n",
    "    # Used to reduce noise.  Increase value for noisy images. (0-10)\n",
    "    damping = 0\n",
    "    # If set, the deconvolved images will be clipped by this percent for max and min values, and then scaled to full range of bit depth. (0-5)\n",
    "    hist_clip = 0.01\n",
    "    # Percent change between iterations to use as criteria to stop deconvolution.\n",
    "    stop_criterion = 5.00\n",
    "    # Percent maximum GPU or CPU memory \n",
    "    max_memory = 0.7\n",
    "    # Enter 'GPU' or 'CPU'\n",
    "    device = 'GPU'\n",
    "    # Chunk size in bytes, or 1 for automatic chunking\n",
    "    blocksize = 3072\n",
    "    # The respective excitation and emission wavelength in nanometers for each channel\n",
    "    wavelengths = {\n",
    "        1: (358, 461),\n",
    "        2: (753, 775),\n",
    "        3: (560, 575),\n",
    "        4: (648, 668)\n",
    "    }\n",
    "    \n",
    "    decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "    source = os.path.join(stitch_dir, f\"cyc{str(dec_cycle).zfill(2)}\", f\"CH{dec_channel}\")\n",
    "    dest = os.path.join(decon_dir, f\"cyc{str(dec_cycle).zfill(2)}\", f\"CH{dec_channel}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    command = [source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_criterion), str(max_memory), device, str(blocksize)]\n",
    "\n",
    "    if os_system == \"Windows\":\n",
    "\n",
    "        decon_exe = os.path.join(base_dir, \"KINTSUGI\", \"KDecon_v4.exe\") \n",
    "        command.insert(0, decon_exe)\n",
    "        ex_index, em_index = 7, 8\n",
    "\n",
    "    if os_system == \"Linux\":\n",
    "\n",
    "        mat_dir = \"/usr/local/MATLAB/MATLAB_Runtime/R2024a/\" \n",
    "        decon_exe = os.path.join(base_dir, \"KINTSUGI\", \"for_distribution_files_only\", \"run_K_Decon_v4.sh\")\n",
    "        command.insert(0, decon_exe)\n",
    "        command.insert(1, mat_dir)\n",
    "        ex_index, em_index = 8, 9\n",
    "\n",
    "    ex, em = wavelengths[dec_channel]\n",
    "    command.insert(ex_index, str(ex))\n",
    "    command.insert(em_index, str(em))\n",
    "\n",
    "    run_subprocess(command)\n",
    "    os.rename(os.path.join(source, 'deconvolved'), os.path.join(dest, 'deconvolved'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6e5d-b464-4f7d-bf8f-d3c542249366",
   "metadata": {},
   "source": [
    "To apply the above decon function to multiple cycles/channels, enter the start and end numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd44c0-b01d-473e-ade7-da609559d9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decon_start_cycle = 1\n",
    "decon_end_cycle = 13\n",
    "\n",
    "decon_start_channel = 1\n",
    "decon_end_channel = 4\n",
    "\n",
    "total_operations = (decon_end_cycle - decon_start_cycle + 1) * (decon_end_channel - decon_start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(decon_start_cycle, decon_end_cycle+1):\n",
    "        for j in range(decon_start_channel, decon_end_channel+1):\n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            decon(base_dir, stitch_dir, i, j)\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948e5f2",
   "metadata": {},
   "source": [
    "## 5. FIJI Clij2 plugin - EDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3e1ac",
   "metadata": {},
   "source": [
    "See the previous notebook for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3363a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiji_dir = os.path.join(base_dir, \"Fiji.app\")\n",
    "javahome = os.path.join(base_dir, \"KINTSUGI\", \"jdk-21_windows-x64_bin\", \"jdk-21.0.5\", \"bin\")\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "mavenhome = os.path.join(base_dir, 'KINTSUGI','apache-maven-3.9.9-bin','apache-maven-3.9.9', 'bin')\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "ij_mem = 50\n",
    "scyjava.config.add_option(f'-Xmx{str(ij_mem)}g')\n",
    "ij = imagej.init(fiji_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4816e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = cl.get_platforms()\n",
    "for platform in platforms:\n",
    "    print(f\"Platform: {platform.name}\")\n",
    "    devices = platform.get_devices()\n",
    "    for device in devices:\n",
    "        print(f\"  Device: {device.name} - Type: {cl.device_type.to_string(device.type)}\")\n",
    "\n",
    "cpu_device = None\n",
    "for platform in platforms:\n",
    "    devices = platform.get_devices()\n",
    "    for device in devices:\n",
    "        if device.type == cl.device_type.CPU:\n",
    "            cpu_device = device\n",
    "            break\n",
    "    if cpu_device:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ceac06-e6aa-41d0-bbbf-263d7e6d0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_start_cycle = 1\n",
    "edf_end_cycle = 13\n",
    "\n",
    "edf_start_channel = 1\n",
    "edf_end_channel = 4\n",
    "\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "edf_dir = decon_dir.replace('_Decon', '_EDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f8217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"NVIDIA RTX A4500\"\n",
    "\n",
    "radius_x = 5\n",
    "radius_y = 5\n",
    "sigma = 20.0\n",
    "\n",
    "xSplit = 3\n",
    "ySplit = 3\n",
    "\n",
    "z_start = 3\n",
    "z_end = 15\n",
    "\n",
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b5e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = \"\"\"\n",
    "#@ File in_folder\n",
    "#@ String device\n",
    "#@ File out_folder\n",
    "#@ String file_name\n",
    "#@ Integer radius_x\n",
    "#@ Integer radius_y\n",
    "#@ Float sigma\n",
    "#@ Integer xTiles\n",
    "#@ Integer yTiles\n",
    "#@ String z_start\n",
    "#@ String z_end\n",
    "#@ Boolean GPU\n",
    "\n",
    "run(\"CLIJ2 Macro Extensions\", \"cl_device=[\" + device + \"] automatic_output_naming=false\");\n",
    "Ext.CLIJ2_clear();\n",
    "//setBatchMode(true);\n",
    "\n",
    "File.openSequence(in_folder);\n",
    "Stack.getDimensions(width, height, channels, slices, frames);\n",
    "\n",
    "if (slices != z_end - z_start + 1) {\n",
    "    run(\"Slice Keeper\", \"first=\" + z_start + \" last=\" + z_end + \" increment=1\");\n",
    "    input = \"deconvolved kept stack\";\n",
    "    Stack.getDimensions(width, height, channels, slices, frames);\n",
    "    } else {\n",
    "    input = \"deconvolved\";\n",
    "}\n",
    "\n",
    "if (GPU == true) {\n",
    "\toutput = \"output\";\n",
    "\tnewImage(output, \"16-bit black\", width, height, 1);\n",
    "    } else {\n",
    "    Ext.CLIJ2_push(input);\n",
    "\tExt.CLIJ2_create2D(output, width, height, 16);\n",
    "}\n",
    "\n",
    "numTilesZ = 1;\n",
    "numTilesX = xTiles;\n",
    "numTilesY = yTiles;\n",
    "\n",
    "tileDepth = round((slices/numTilesZ));\n",
    "tileWidth = round((width/numTilesX));\n",
    "tileHeight = round((height/numTilesY));\n",
    "\n",
    "for (x = 0; x < numTilesX; x++) {\n",
    "\tfor (y = 0; y < numTilesY; y++) {\n",
    "\t\tfor (z = 0; z < numTilesZ; z++) {\n",
    "\n",
    "\t\t\tExt.CLIJ2_pushTile(input, x, y, z, tileWidth, tileHeight, tileDepth, 0, 0, 0);\t\t\n",
    "\t\t\tExt.CLIJ2_extendedDepthOfFocusVarianceProjection(input, output, radius_x, radius_y, sigma);\n",
    "            Ext.CLIJ2_release(input);\n",
    "            if (GPU == true) {\n",
    "\t\t\t\tExt.CLIJ2_pullTile(output, x, y, z, tileWidth, tileHeight, 1, 0, 0, 0);\n",
    "\t\t\t\tExt.CLIJ2_release(output);\n",
    "\t\t\t}            \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "if (GPU == false) {\n",
    "\tExt.CLIJ2_pull(output);\n",
    "    Ext.CLIJ2_release(output);\n",
    "}\n",
    "\n",
    "selectImage(output);\n",
    "saveAs(\"Tiff\", out_folder + File.separator + file_name);\n",
    "\n",
    "Ext.CLIJ2_clear();\n",
    "run(\"Close All\");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1945ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c22c528377447e9286560908ad404e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/52 [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Operating in headless mode - the original ImageJ will have limited functionality.\n"
     ]
    }
   ],
   "source": [
    "total_operations = (edf_end_cycle - edf_start_cycle + 1) * (edf_end_channel - edf_start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(edf_start_cycle, edf_end_cycle+1):\n",
    "        edf_dest = os.path.join(edf_dir, f\"cyc{str(i).zfill(2)}\")\n",
    "        os.makedirs(edf_dest, exist_ok=True)\n",
    "        \n",
    "        for j in range(edf_start_channel, edf_end_channel+1):\n",
    "\n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            edf_source = os.path.join(decon_dir, f\"cyc{str(i).zfill(2)}\", f\"CH{str(j)}\", \"deconvolved\")\n",
    "            file_name = channel_name_dict.get(f\"cyc{str(i).zfill(2)}.tif\")[j-1]\n",
    "            \n",
    "\n",
    "            args = {'in_folder': edf_source, \n",
    "                    \"device\" : device, \n",
    "                    \"out_folder\" : edf_dest, \n",
    "                    \"file_name\" : file_name, \n",
    "                    \"radius_x\" : radius_x, \n",
    "                    \"radius_y\" : radius_y, \n",
    "                    \"sigma\" : sigma, \n",
    "                    \"xTiles\" : xSplit, \n",
    "                    \"yTiles\" : ySplit, \n",
    "                    \"z_start\" : z_start, \n",
    "                    \"z_end\" : z_end, \n",
    "                    \"GPU\" : GPU}\n",
    "\n",
    "            ij.py.run_macro(macro, args)\n",
    "\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c5fe8",
   "metadata": {},
   "source": [
    "## 6. Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f386fb",
   "metadata": {},
   "source": [
    "- Registration is performed using the VALIS program https://valis.readthedocs.io/en/stable/examples.html. \n",
    "- In the following cell, the images produced in Section 5 are combined to multi-channel tif files in a format the VALIS program is compatible with.\n",
    "- Enter the cycles being processed, the data_type desired, and the pixel size.\n",
    "- The metadata and parameters for pyramidal output may be changed.\n",
    "- Be sure the path to the vips binaries is defined correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c6a31",
   "metadata": {},
   "source": [
    "### 6.1 Combine channels for each cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_start_cycle = 1\n",
    "reg_end_cycle = 13\n",
    "data_type = \"uint16\"  \n",
    "pixel_size = float(0.377)\n",
    "\n",
    "logging.basicConfig(level=logging.WARN) #change to INFO for more details\n",
    "\n",
    "if os_system == \"Windows\":\n",
    "    vipshome = os.path.join(base_dir, 'KINTSUGI','vips-dev-8.16','bin')\n",
    "    os.environ['PATH'] = vipshome + ';' + os.environ['PATH']\n",
    "\n",
    "import pyvips \n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "os.makedirs(reg_dir, exist_ok=True)\n",
    "\n",
    "pbar_filesave = tqdm(total=100, unit=\"Percent\",\n",
    "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True)\n",
    "\n",
    "for j in range(reg_start_cycle, reg_end_cycle + 1):\n",
    "\n",
    "    cycle= f\"cyc{str(j).zfill(2)}\" \n",
    "     \n",
    "    reg_source = os.path.join(edf_dir, f\"cyc{str(j).zfill(2)}\") \n",
    "    image_set = glob(os.path.join(reg_source, '*.tif'))\n",
    "    channel_name_order = channel_name_dict.get(f\"cyc{str(j).zfill(2)}.tif\")\n",
    "    image_set.sort(key=lambda x: channel_name_order.index(os.path.basename(x).split('.')[0]))\n",
    "  \n",
    "    channel_names = []\n",
    "    for i in range(len(image_set)):\n",
    "        split_name = os.path.basename(image_set[i].split(\".\")[0])\n",
    "        channel_names.append(split_name)\n",
    " \n",
    "    pyvips_image_set = [pyvips.Image.new_from_file(os.path.join(reg_source, filename), access=\"sequential\") for filename in image_set]\n",
    "\n",
    "    out_init = pyvips.Image.arrayjoin(pyvips_image_set, across=1)\n",
    "    out = out_init.copy()\n",
    "    out.set_type(pyvips.GValue.gint_type, \"page-height\", pyvips_image_set[0].height)\n",
    "\n",
    "    x_dim = pyvips_image_set[0].width\n",
    "    y_dim = pyvips_image_set[0].height\n",
    "\n",
    "    bands = len(pyvips_image_set)\n",
    "    outfile = os.path.join(reg_dir, f'cyc{str(j).zfill(2)}.ome.tif')\n",
    "    out.set_type(pyvips.GValue.gstr_type, \"image-description\",\n",
    "    f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "        <OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "            xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "            xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\">\n",
    "            <Image ID=\"Image:0\" Name=\"{cycle}\" >\n",
    "                <!-- Minimum required fields about image dimensions -->\n",
    "                <Pixels BigEndian=\"false\"\n",
    "                        DimensionOrder=\"XYCZT\" \n",
    "                        ID=\"Pixels:0\"\n",
    "                        Interleaved=\"false\"\n",
    "                        SignificantBits=\"16\"                                              \n",
    "                        SizeC=\"{bands}\" \n",
    "                        SizeT=\"1\" \n",
    "                        SizeX=\"{x_dim}\" \n",
    "                        SizeY=\"{y_dim}\" \n",
    "                        SizeZ=\"1\" \n",
    "                        Type=\"{data_type}\" \n",
    "                        PhysicalSizeX=\"{pixel_size}\" \n",
    "                        PhysicalSizeY=\"{pixel_size}\">\n",
    "                    <TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"16751615\" ID=\"Channel:0:0\" Name=\"{channel_names[0]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"1\" FirstT=\"0\" FirstZ=\"0\" IFD=\"1\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"7995391\" ID=\"Channel:0:1\" Name=\"{channel_names[1]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"2\" FirstT=\"0\" FirstZ=\"0\" IFD=\"2\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"9043967\" ID=\"Channel:0:2\" Name=\"{channel_names[2]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"3\" FirstT=\"0\" FirstZ=\"0\" IFD=\"3\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"1828651263\" ID=\"Channel:0:3\" Name=\"{channel_names[3]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                </Pixels>\n",
    "            </Image>\n",
    "        </OME>\"\"\")\n",
    "\n",
    "    out.tiffsave(outfile, subifd=True, page_height=y_dim, compression='lzw', tile=True,\n",
    "                  tile_width=512, tile_height=512, pyramid=True, bigtiff=True)\n",
    "    out_init = None\n",
    "    out = None\n",
    "    pyvips_image_set = None\n",
    "    gc.collect() \n",
    "    pbar_filesave.update(100 / (reg_end_cycle - reg_start_cycle + 1))\n",
    "\n",
    "pbar_filesave.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3abfed",
   "metadata": {},
   "source": [
    "### 6.2 VALIS Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc26d2",
   "metadata": {},
   "source": [
    "- See https://github.com/MathOnco/valis/tree/main for full documentation. \n",
    "The process for registration involves producing registration data on the rigid and non-rigid movement of the images relative to one another to bring about alignment as they overlap.  This data is inspected for accuracy as the writing of the registered images takes a long time.  There is an optional micro-registration if smaller structure overlap is important.  Either way, the registration results to be used for the image registration is stored in the results_dst_dir as a .pickle file.\n",
    "- According to the VALIS docs: One of the most important parameters used to initialize a Valis object is max_processed_image_dim_px, which determines the size of the image used to find the rigid registration parameters. The default value is 850, but if registration fails or is poor, try adjusting that value. Generally speaking, values between 500-2000 work well. In cases where there is little empty space around the tissue, smaller values may be better. However, if there is a large amount of empty space/slide (as in the images above), larger values may be needed so that the tissue is at a high enough resolution. To improve alignment of the finer details in the images, larger images can be used in the non-rigid or micro-registration steps (set via the max_non_rigid_registration_dim_px parameter).\n",
    "- If you get an error that the jvm is not found, try uncommenting the registration.init_jvm() line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d56ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_system = platform.system()\n",
    "if os_system == \"Windows\":\n",
    "    vipsbin = os.path.join(base_dir, 'KINTSUGI','vips-dev-8.16','bin')\n",
    "    os.environ['PATH'] = vipsbin + ';' + os.environ['PATH']\n",
    "javahome = os.path.join(base_dir, \"KINTSUGI\", \"jdk-21_windows-x64_bin\", \"jdk-21.0.5\", \"bin\")\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "mavenhome = os.path.join(base_dir, 'KINTSUGI','apache-maven-3.9.9-bin','apache-maven-3.9.9', 'bin')\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "from valis import registration\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# registration.init_jvm()\n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "\n",
    "slide_src_dir = reg_dir\n",
    "results_dst_dir = os.path.join(reg_dir, \"valis_out\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345b551",
   "metadata": {},
   "source": [
    "- Running this cell will produce registration data, but will not register the images, allowing for testing different parameters.\n",
    "\n",
    "- Note that if you rerun the registration, results will be overwritten.  To avoid this you will need to rename your results_dst_dir folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08fb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_processed_image_dim_px = 600\n",
    "registrar = registration.Valis(slide_src_dir, results_dst_dir, crop=\"overlap\", max_processed_image_dim_px = max_processed_image_dim_px, imgs_ordered=True)\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ec5c5",
   "metadata": {},
   "source": [
    "- Review the results in the produced registration folder saved in “valis_out”\n",
    "- A quick method is to scroll through the “deformation_fields” images below.  Be cautious of angular deformations.  Other options to view by replacing \"deformation_fields\" below: \"masks\", \"non_rigid_registration\", \"processed\", and \"rigid_registration\".\n",
    "- To view the output, you may need to click the ellipses next to the output cell and click \"Change Presentation\" to choose IPyWidgetRenderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b4430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other options to view by replacing \"deformation_fields\" below: \"masks\", \"non_rigid_registration\", \"processed\", and \"rigid_registration\".\n",
    "im_raw_deform = glob(os.path.join(reg_dir, \"valis_out\", os.path.basename(reg_dir), \"deformation_fields\", \"*.png\"))\n",
    "im_deform = imread_collection(im_raw_deform)\n",
    "deform = np.asarray(im_deform).astype(np.uint8)\n",
    "\n",
    "stackview.slice(deform, zoom_factor=1.6, continuous_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024707a",
   "metadata": {},
   "source": [
    "- Micro-registration takes much longer (e.g. standard ~5-10 min and micro ~2-3 hrs) than standard registration.  Be sure to test a few changes to the standard method before switching to micro.\n",
    "- If further refining of results is warranted, the optional micro-registration may be run.\n",
    "- Note that the previous registration is saved to the .pickle file in path_to_register.  This will be overwritten by the micro-registration results.  To avoid this, rename the .pickle file.\n",
    "- The cell below determines the parameter to use based on 25% of original resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68de6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_reg_fraction = 0.25\n",
    "img_dims = np.array([slide_obj.slide_dimensions_wh[0] for slide_obj in registrar.slide_dict.values()])\n",
    "print(img_dims)\n",
    "min_max_size = np.min([np.max(d) for d in img_dims])\n",
    "img_areas = [np.multiply(*d) for d in img_dims]\n",
    "max_img_w, max_img_h = tuple(img_dims[np.argmax(img_areas)])\n",
    "micro_reg_size = np.floor(min_max_size*micro_reg_fraction).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valis.micro_rigid_registrar import MicroRigidRegistrar\n",
    "\n",
    "micro_results_dst_dir = os.path.join(reg_dir, \"valis_out_micro\")\n",
    "registrar = registration.Valis(slide_src_dir, micro_results_dst_dir, micro_rigid_registrar_cls=MicroRigidRegistrar)\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "micro_reg, micro_error = registrar.register_micro(max_non_rigid_registration_dim_px=micro_reg_size)\n",
    "matches_dst_dir = os.path.join(registrar.dst_dir, \"hi_rez_matches\")\n",
    "registrar.draw_matches(matches_dst_dir)\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c190f53",
   "metadata": {},
   "source": [
    "- Review the results of micro-registration.\n",
    "- New output will be for \"deformation_fields\", \"micro_registration\", \"non_rigid_registration\", \"overlaps\", and \"hi_rez_matches\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_raw_micro = glob(os.path.join(reg_dir, \"valis_out\", os.path.basename(reg_dir), \"deformation_fields\", \"*.png\"))\n",
    "im_micro = imread_collection(im_raw_micro)\n",
    "micro = np.asarray(im_micro).astype(np.uint8)\n",
    "\n",
    "stackview.slice(micro, zoom_factor=1.6, continuous_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c8b01",
   "metadata": {},
   "source": [
    "Here is where the application of the registration to the images occurs.  The first cell merges all images to one file, while the second creates one image per cycle. If multiple rounds of testing was done, be sure you are using the final .pickle file for the final image creation.\n",
    "- At this point, images are likely not the same size.  Using the crop function will crop all images to the same size.  This is necessary to use image math functions in the next notebook.\n",
    "- Naming is based on the definitions of “channel_name_dict” defined above.  It may be necessary to run that cell again.\n",
    "- The registration of the common first channel will effectively align the rest of the channels in each cycle to one another.\n",
    "- Note that writting large image files generally takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3e78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52935c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_slide_dst_f = os.path.join(results_dst_dir, \"merged.ome.tif\")\n",
    "path_to_registrar = os.path.join(reg_dir, \"valis_out\", os.path.basename(reg_dir),\"data\", os.path.basename(reg_dir)+\"_registrar.pickle\")\n",
    "registrar = registration.load_registrar(path_to_registrar)\n",
    "\n",
    "merged_img, channel_names, ome_xml = registrar.warp_and_merge_slide(merged_slide_dst_f,\n",
    "                                    crop=\"reference\",\n",
    "                                    drop_duplicates=True, \n",
    "                                    compression=\"jp2k\",\n",
    "                                    Q=90,\n",
    "                                    pyramid=False)\n",
    "\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e35b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_registrar = os.path.join(reg_dir, \"valis_out\", os.path.basename(reg_dir),\"data\", os.path.basename(reg_dir)+\"_registrar.pickle\")\n",
    "registrar = registration.load_registrar(path_to_registrar)\n",
    "\n",
    "for slide_name, slide_obj in registrar.slide_dict.items():\n",
    "    reg_dir_out = os.path.join(reg_dir, \"registered\")\n",
    "    os.makedirs(reg_dir_out, exist_ok=True)\n",
    "    dst_f = os.path.join(reg_dir_out, f\"{slide_name}.ome.tif\")\n",
    "    slide_obj.warp_and_save_slide(dst_f=dst_f, \n",
    "                                  crop=\"reference\",                                  \n",
    "                                  compression=\"jp2k\", \n",
    "                                  Q=90,\n",
    "                                  pyramid=False)\n",
    "\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a1a1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KINTSUGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
