{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de152bce-3aae-4e74-b337-ff06e0345601",
   "metadata": {},
   "source": [
    "# Part 2: Batch Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b9b613-22fc-40c7-a4a3-e5f0b1cb9f73",
   "metadata": {},
   "source": [
    "In the following notebook you will use the parameters found in A_Evaluation&Testing.ipynb to correct and stitch entire datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20908051-79d7-4e17-8725-587ca5084c2b",
   "metadata": {},
   "source": [
    "## 1. Import packages. \n",
    "*This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b61c7f-445a-466f-a3d3-dfefa0d45258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import gc\n",
    "import os as os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import KCorrect\n",
    "from Kstitch.stitching import stitch_images\n",
    "from glob import glob\n",
    "from skimage.io.collection import alphanumeric_key\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection, imsave\n",
    "import stackview\n",
    "import numpy as np\n",
    "from itertools import chain, repeat\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import imagej, scyjava\n",
    "import logging\n",
    "import pyopencl as cl\n",
    "import warnings\n",
    "import platform\n",
    "os_system = platform.system()\n",
    "current_dateTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2ab6-e1f7-45b0-96c2-a2a691807caf",
   "metadata": {},
   "source": [
    "## 2. Define directory paths. \n",
    "*This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b6a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"C:\\\\Users\\\\smith6jt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2736065-d891-45e8-a56e-8190ce6028e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_raw.\n",
      "Stitching folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_BaSiC_Stitched.\n",
      "Meta folder is C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_meta.\n"
     ]
    }
   ],
   "source": [
    "image_dir = os.path.join(base_dir, 'KINTSUGI', 'data', '1904_CC2B_raw')\n",
    "stitch_dir = image_dir.replace(\"_raw\", \"_BaSiC_Stitched\")\n",
    "meta_dir = stitch_dir.replace(\"_BaSiC_Stitched\", \"_meta\")\n",
    "project_file = os.path.join(meta_dir, \"project_data.txt\")\n",
    "print(f\"Image folder is {image_dir}.\")\n",
    "print(f\"Stitching folder is {stitch_dir}.\")\n",
    "print(f\"Meta folder is {meta_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986ebe1-7f2e-4591-b8df-a6dbd6a21eeb",
   "metadata": {},
   "source": [
    "## 3. Stitching and Illumination Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad713805",
   "metadata": {},
   "source": [
    "### 3.1 Stitching Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9d7e45",
   "metadata": {},
   "source": [
    "- The following cell defines the function that is called from the apply_basic function to stitch the corrected tiles.  \n",
    "- It creates a file with the stitching positions calculated from the middle z-plane images of the first channel.\n",
    "- The file is then used to stitch the rest of the images for all channels in the cycle. BECAUSE OF THIS, YOU MUST HAVE RUN THE FIRST CHANNEL OF A CYCLE TO STITCH THE OTHER CHANNELS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8598a778-b89c-4872-a1c6-a03819c37d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch(images_transformed, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu):\n",
    "    \n",
    "    z = str(zplanes)\n",
    "    ch = str(channels)\n",
    "    pkl_dest = os.path.join(dest, \"result_df.pkl\")\n",
    "    \n",
    "    if zplanes == zplanes_n//2 and channels == 1:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(pkl_dest):\n",
    "            result_df = pd.read_pickle(pkl_dest)\n",
    "        else:\n",
    "            result_df, _ = stitch_images(images_transformed, rows, cols, initial_ncc_threshold=0.0, overlap_percentage=overlap_percentage, pou=pou, use_gpu=use_gpu)\n",
    "            result_df.to_pickle(pkl_dest)\n",
    "           \n",
    "        \n",
    "    else:\n",
    "        print(f\"Start Stitching Z0{z.zfill(2)}_CH{ch}\")\n",
    "        if os.path.exists(os.path.join(dest_1, \"result_df.pkl\")):\n",
    "            result_df = pd.read_pickle(os.path.join(dest_1, \"result_df.pkl\"))\n",
    "\n",
    "        else:\n",
    "            print(\"Run registration channel to produce a stitching model.\")\n",
    "\n",
    "    result_df[\"y_pos2\"] = result_df[\"y_pos\"] - result_df[\"y_pos\"].min()\n",
    "    result_df[\"x_pos2\"] = result_df[\"x_pos\"] - result_df[\"x_pos\"].min()\n",
    "    \n",
    "    size_y = images_transformed.shape[1]\n",
    "    size_x = images_transformed.shape[2]\n",
    "    \n",
    "    stitched_image_size = (\n",
    "        result_df[\"y_pos2\"].max() + size_y,\n",
    "        result_df[\"x_pos2\"].max() + size_x,\n",
    "    )\n",
    "    stitched_image = np.zeros_like(images_transformed, shape=stitched_image_size)\n",
    "    \n",
    "    for i, row in result_df.iterrows():\n",
    "        stitched_image[\n",
    "            row[\"y_pos2\"] : row[\"y_pos2\"] + size_y,\n",
    "            row[\"x_pos2\"] : row[\"x_pos2\"] + size_x,\n",
    "        ] = images_transformed[i]\n",
    "\n",
    "    result_image_file_path = os.path.join(dest,f\"{z.zfill(2)}.tif\") \n",
    "    imsave(result_image_file_path, stitched_image, check_contrast=False)\n",
    "    \n",
    "    print(f\"Saved to {result_image_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ff441",
   "metadata": {},
   "source": [
    "### 3.2 Illumination Correction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4328b6a-0eb6-4499-9e7e-27f040a60a14",
   "metadata": {},
   "source": [
    "- The following cell contains the function that will apply the illumination correction to your data.  \n",
    "- Change the five variables below according to tests using the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725a6802-1694-4881-85cf-21821ba0439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu):\n",
    "\n",
    "    if_darkfield = True\n",
    "    max_iterations = 500\n",
    "    optimization_tolerance = 1e-6\n",
    "    max_reweight_iterations = 25\n",
    "    reweight_tolerance = 1.0e-3\n",
    "\n",
    "    filename_pattern = f'1_000??_Z0{str(zplanes).zfill(2)}_CH{str(channels)}.tif'\n",
    "    \n",
    "    dest = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", f\"CH{str(channels)}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "    dest_1 = os.path.join(stitch_dir, f\"cyc{str(cycles).zfill(2)}\", \"CH1\")\n",
    "    \n",
    "    im_raw = sorted(glob(os.path.join(image_dir, f'cyc{str(cycles).zfill(3)}', filename_pattern)), key=alphanumeric_key)\n",
    "    im = imread_collection(im_raw)\n",
    "    im_array_init = np.asarray(im)\n",
    "    dtype_max = np.iinfo(im_array_init.dtype).max\n",
    "    im_array = im_array_init.astype(np.float64) / dtype_max\n",
    "\n",
    "    if not np.all(np.isfinite(im_array)):\n",
    "        raise ValueError(\"Input array contains inf or nan values\")\n",
    "    if np.any(im_array < 0):\n",
    "        raise ValueError(\"Input array contains negative values\")\n",
    "\n",
    "    print(f\"Start Illumination Correction cyc{str(cycles).zfill(2)} Z0{str(zplanes).zfill(2)}_CH{str(channels)}\")\n",
    "    flatfield, darkfield = KCorrect.KCorrect(im_array, if_darkfield = if_darkfield, max_iterations = max_iterations, optimization_tolerance = optimization_tolerance,  max_reweight_iterations = max_reweight_iterations, reweight_tolerance = reweight_tolerance)\n",
    "    \n",
    "    if np.any(np.isnan(flatfield)) or np.any(np.isnan(darkfield)):\n",
    "        raise ValueError(\"Invalid flatfield or darkfield correction\")\n",
    "    if np.any(flatfield == 0):\n",
    "        warnings.warn(\"Flatfield contains zero values which may cause division issues\")\n",
    "    \n",
    "    corrected = np.zeros_like(im_array, dtype=np.float64)\n",
    "    for i in range(len(im_array)):\n",
    "        corrected[i] = ((im_array[i] - darkfield) / flatfield)\n",
    "        corrected[i] = np.clip(corrected[i], 0, 1)\n",
    "        \n",
    "    KCorrect.validate_correction(im_array_init, corrected)\n",
    "    corrected = (corrected * dtype_max).astype(np.uint16)                                       \n",
    "    stitch(corrected, zplanes, dest, dest_1, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4627091e-c1aa-4a7e-b6ef-a570bf28932d",
   "metadata": {},
   "source": [
    "### 3.3 Running Multiple Cycle/Channel Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db18604-75ad-4533-a9f9-b5dbe9785475",
   "metadata": {},
   "source": [
    "- This cell runs the above two functions for all the images you define with start_cycle, end_cycle, start_channel, and end_channel.  \n",
    "- Enter values for n, m, pou (determined from the first notebook), zplanes_n (number of zplanes), and overlap_percentage.  \n",
    "- Enter the number of workers for the multithreading (usually determined by dataset size, available memory, and number of cores).  See https://docs.python.org/3/library/concurrent.futures.html\n",
    "- To run just one cycle or channel, simply enter the same number for both start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 9  # Number of rows (height)\n",
    "m = 7  # Number of columns (width)\n",
    "start_cycle = 1\n",
    "end_cycle = 13\n",
    "start_channel = 1\n",
    "end_channel = 4\n",
    "pou = 13\n",
    "zplanes_n = 17\n",
    "overlap_percentage = 0.30\n",
    "workers = zplanes_n-1\n",
    "use_gpu = True\n",
    "\n",
    "# Row coordinates: each row index is repeated m times\n",
    "rows = list(chain.from_iterable(repeat(row, m) for row in range(n)))\n",
    "# Column coordinates: snake pattern for each row, going back and forth from top left going right\n",
    "cols = list(chain.from_iterable(range(m) if row % 2 == 0 else range(m - 1, -1, -1) for row in range(n)))\n",
    "\n",
    "image_dir_list = [image_dir] * (zplanes_n-1)\n",
    "stitch_dir_list = [stitch_dir] * (zplanes_n-1)\n",
    "zplanes_list =[zplanes_n] * (zplanes_n-1)\n",
    "pou_list = [pou] * (zplanes_n-1)\n",
    "rows_list = [rows] * (zplanes_n-1)\n",
    "cols_list = [cols] * (zplanes_n-1)\n",
    "overlap_percentage_list = [overlap_percentage] * (zplanes_n-1)\n",
    "use_gpu_list = [use_gpu] * (zplanes_n-1)\n",
    "\n",
    "\n",
    "total_operations = (end_cycle - start_cycle + 1) * (end_channel - start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(start_cycle, end_cycle+1):\n",
    "        for j in range(start_channel, end_channel+1):\n",
    "            \n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            cycles = i\n",
    "            zplanes = zplanes_n//2 \n",
    "            channels = j\n",
    "            apply_KCorrect(image_dir, stitch_dir, zplanes, cycles, channels, zplanes_n, pou, rows, cols, overlap_percentage, use_gpu)\n",
    "            \n",
    "            if __name__ ==  '__main__':\n",
    "                with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "                    cycles = [i] * (zplanes_n-1) \n",
    "                    zplanes =  list(range(1, zplanes_n//2))+list(range((zplanes_n//2)+1, zplanes_n+1)) \n",
    "                    channels = [j] * (zplanes_n-1)\n",
    "                    executor.map(apply_KCorrect, image_dir_list, stitch_dir_list, zplanes, cycles, channels, zplanes_list, pou_list, rows_list, cols_list, overlap_percentage_list, use_gpu_list) \n",
    "\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3723d-e254-4bd1-bb5b-639f35e66dcc",
   "metadata": {},
   "source": [
    "## 4. Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fefaab-7c4a-4624-b85f-f26644b967f6",
   "metadata": {},
   "source": [
    "- See the first notebook for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2ca0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_subprocess(command):\n",
    "    \n",
    "    process = subprocess.Popen(command, \n",
    "                                stdout=subprocess.PIPE, \n",
    "                                stderr=subprocess.STDOUT, \n",
    "                                shell=True, \n",
    "                                bufsize=1,\n",
    "                                universal_newlines=True, \n",
    "                                text=True)\n",
    "    \n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == '' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output, end='') \n",
    "\n",
    "    rc = process.poll()\n",
    "    return rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a9e249-9b51-4bde-b711-0a40ddcd8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decon(base_dir, stitch_dir, dec_cycle, dec_channel):\n",
    "\n",
    "    # pixel size in xy dimension (nanometers)\n",
    "    xy_vox = 377\n",
    "    # pixel size in z dimension (nanometers)\n",
    "    z_vox = 1500\n",
    "    # Number of iterations of Lucy-Richardson algo before stopping unless stop_crit is met first\n",
    "    iterations = 25\n",
    "    # Microscope objective numerical aperture\n",
    "    mic_NA = 0.75\n",
    "    # Refractive index of tissue being imaged\n",
    "    tissue_RI = 1.44\n",
    "    # Opening size in millimeters of objective aperture\n",
    "    slit_aper = 6.5\n",
    "    # Focal length in millimeters of objective\n",
    "    f_cyl = 1\n",
    "    # Used to reduce noise.  Increase value for noisy images. (0-10)\n",
    "    damping = 0\n",
    "    # If set, the deconvolved images will be clipped by this percent for max and min values, and then scaled to full range of bit depth. (0-5)\n",
    "    hist_clip = 0.01\n",
    "    # Percent change between iterations to use as criteria to stop deconvolution.\n",
    "    stop_criterion = 5.00\n",
    "    # Percent maximum GPU or CPU memory \n",
    "    max_memory = 0.7\n",
    "    # Enter 'GPU' or 'CPU'\n",
    "    device = 'GPU'\n",
    "    # Chunk size in bytes, or 1 for automatic chunking\n",
    "    blocksize = 3072\n",
    "    # The respective excitation and emission wavelength in nanometers for each channel\n",
    "    wavelengths = {\n",
    "        1: (358, 461),\n",
    "        2: (753, 775),\n",
    "        3: (560, 575),\n",
    "        4: (648, 668)\n",
    "    }\n",
    "    \n",
    "    decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "    source = os.path.join(stitch_dir, f\"cyc{str(dec_cycle).zfill(2)}\", f\"CH{dec_channel}\")\n",
    "    dest = os.path.join(decon_dir, f\"cyc{str(dec_cycle).zfill(2)}\", f\"CH{dec_channel}\")\n",
    "    os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "    command = [source, str(xy_vox), str(z_vox), str(iterations), str(mic_NA), str(tissue_RI), str(f_cyl), str(slit_aper), str(damping), str(hist_clip), str(stop_criterion), str(max_memory), device, str(blocksize)]\n",
    "\n",
    "    if os_system == \"Windows\":\n",
    "\n",
    "        decon_exe = os.path.join(base_dir, \"KINTSUGI\", \"KDecon_v4.exe\") \n",
    "        command.insert(0, decon_exe)\n",
    "        ex_index, em_index = 7, 8\n",
    "\n",
    "    if os_system == \"Linux\":\n",
    "\n",
    "        mat_dir = \"/usr/local/MATLAB/MATLAB_Runtime/R2024a/\" \n",
    "        decon_exe = os.path.join(base_dir, \"KINTSUGI\", \"for_distribution_files_only\", \"run_K_Decon_v4.sh\")\n",
    "        command.insert(0, decon_exe)\n",
    "        command.insert(1, mat_dir)\n",
    "        ex_index, em_index = 8, 9\n",
    "\n",
    "    ex, em = wavelengths[dec_channel]\n",
    "    command.insert(ex_index, str(ex))\n",
    "    command.insert(em_index, str(em))\n",
    "\n",
    "    run_subprocess(command)\n",
    "    os.rename(os.path.join(source, 'deconvolved'), os.path.join(dest, 'deconvolved'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60df6e5d-b464-4f7d-bf8f-d3c542249366",
   "metadata": {},
   "source": [
    "To apply the above decon function to multiple cycles/channels, enter the start and end numbers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd44c0-b01d-473e-ade7-da609559d9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decon_start_cycle = 1\n",
    "decon_end_cycle = 13\n",
    "\n",
    "decon_start_channel = 1\n",
    "decon_end_channel = 4\n",
    "\n",
    "total_operations = (decon_end_cycle - decon_start_cycle + 1) * (decon_end_channel - decon_start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(decon_start_cycle, decon_end_cycle+1):\n",
    "        for j in range(decon_start_channel, decon_end_channel+1):\n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            decon(base_dir, stitch_dir, i, j)\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8948e5f2",
   "metadata": {},
   "source": [
    "## 5. FIJI Clij2 plugin - EDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3e1ac",
   "metadata": {},
   "source": [
    "See the previous notebook for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3363a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiji_dir = os.path.join(base_dir, \"Fiji.app\")\n",
    "javahome = os.path.join(base_dir, \"KINTSUGI\", \"jdk-21_windows-x64_bin\", \"jdk-21.0.5\", \"bin\")\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "mavenhome = os.path.join(base_dir, 'KINTSUGI','apache-maven-3.9.9-bin','apache-maven-3.9.9', 'bin')\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "ij_mem = 50\n",
    "scyjava.config.add_option(f'-Xmx{str(ij_mem)}g')\n",
    "ij = imagej.init(fiji_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4816e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "platforms = cl.get_platforms()\n",
    "for platform in platforms:\n",
    "    print(f\"Platform: {platform.name}\")\n",
    "    devices = platform.get_devices()\n",
    "    for device in devices:\n",
    "        print(f\"  Device: {device.name} - Type: {cl.device_type.to_string(device.type)}\")\n",
    "\n",
    "cpu_device = None\n",
    "for platform in platforms:\n",
    "    devices = platform.get_devices()\n",
    "    for device in devices:\n",
    "        if device.type == cl.device_type.CPU:\n",
    "            cpu_device = device\n",
    "            break\n",
    "    if cpu_device:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ceac06-e6aa-41d0-bbbf-263d7e6d0845",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "380f3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_start_cycle = 1\n",
    "edf_end_cycle = 13\n",
    "\n",
    "edf_start_channel = 1\n",
    "edf_end_channel = 4\n",
    "\n",
    "decon_dir = stitch_dir.replace('_BaSiC_Stitched', '_Decon')\n",
    "edf_dir = decon_dir.replace('_Decon', '_EDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f8217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"NVIDIA RTX A4500\"\n",
    "\n",
    "radius_x = 5\n",
    "radius_y = 5\n",
    "sigma = 20.0\n",
    "\n",
    "xSplit = 3\n",
    "ySplit = 3\n",
    "\n",
    "z_start = 3\n",
    "z_end = 15\n",
    "\n",
    "GPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b5e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = \"\"\"\n",
    "#@ File in_folder\n",
    "#@ String device\n",
    "#@ File out_folder\n",
    "#@ String file_name\n",
    "#@ Integer radius_x\n",
    "#@ Integer radius_y\n",
    "#@ Float sigma\n",
    "#@ Integer xTiles\n",
    "#@ Integer yTiles\n",
    "#@ String z_start\n",
    "#@ String z_end\n",
    "#@ Boolean GPU\n",
    "\n",
    "run(\"CLIJ2 Macro Extensions\", \"cl_device=[\" + device + \"] automatic_output_naming=false\");\n",
    "Ext.CLIJ2_clear();\n",
    "//setBatchMode(true);\n",
    "\n",
    "File.openSequence(in_folder);\n",
    "Stack.getDimensions(width, height, channels, slices, frames);\n",
    "\n",
    "if (slices != z_end - z_start + 1) {\n",
    "    run(\"Slice Keeper\", \"first=\" + z_start + \" last=\" + z_end + \" increment=1\");\n",
    "    input = \"deconvolved kept stack\";\n",
    "    Stack.getDimensions(width, height, channels, slices, frames);\n",
    "    } else {\n",
    "    input = \"deconvolved\";\n",
    "}\n",
    "\n",
    "if (GPU == true) {\n",
    "\toutput = \"output\";\n",
    "\tnewImage(output, \"16-bit black\", width, height, 1);\n",
    "    } else {\n",
    "    Ext.CLIJ2_push(input);\n",
    "\tExt.CLIJ2_create2D(output, width, height, 16);\n",
    "}\n",
    "\n",
    "numTilesZ = 1;\n",
    "numTilesX = xTiles;\n",
    "numTilesY = yTiles;\n",
    "\n",
    "tileDepth = round((slices/numTilesZ));\n",
    "tileWidth = round((width/numTilesX));\n",
    "tileHeight = round((height/numTilesY));\n",
    "\n",
    "for (x = 0; x < numTilesX; x++) {\n",
    "\tfor (y = 0; y < numTilesY; y++) {\n",
    "\t\tfor (z = 0; z < numTilesZ; z++) {\n",
    "\n",
    "\t\t\tExt.CLIJ2_pushTile(input, x, y, z, tileWidth, tileHeight, tileDepth, 0, 0, 0);\t\t\n",
    "\t\t\tExt.CLIJ2_extendedDepthOfFocusVarianceProjection(input, output, radius_x, radius_y, sigma);\n",
    "            Ext.CLIJ2_release(input);\n",
    "            if (GPU == true) {\n",
    "\t\t\t\tExt.CLIJ2_pullTile(output, x, y, z, tileWidth, tileHeight, 1, 0, 0, 0);\n",
    "\t\t\t\tExt.CLIJ2_release(output);\n",
    "\t\t\t}            \n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "if (GPU == false) {\n",
    "\tExt.CLIJ2_pull(output);\n",
    "    Ext.CLIJ2_release(output);\n",
    "}\n",
    "\n",
    "selectImage(output);\n",
    "saveAs(\"Tiff\", out_folder + File.separator + file_name);\n",
    "\n",
    "Ext.CLIJ2_clear();\n",
    "run(\"Close All\");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1945ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_operations = (edf_end_cycle - edf_start_cycle + 1) * (edf_end_channel - edf_start_channel + 1)\n",
    "\n",
    "with tqdm(total=total_operations, desc='Processing', unit='operation',\n",
    "                    bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True) as pbar:\n",
    "    for i in range(edf_start_cycle, edf_end_cycle+1):\n",
    "        edf_dest = os.path.join(edf_dir, f\"cyc{str(i).zfill(2)}\")\n",
    "        os.makedirs(edf_dest, exist_ok=True)\n",
    "        \n",
    "        for j in range(edf_start_channel, edf_end_channel+1):\n",
    "\n",
    "            pbar.set_description(f'Cycle {i} Channel {j}')\n",
    "            edf_source = os.path.join(decon_dir, f\"cyc{str(i).zfill(2)}\", f\"CH{str(j)}\", \"deconvolved\")\n",
    "            file_name = channel_name_dict.get(f\"cyc{str(i).zfill(2)}.tif\")[j-1]\n",
    "            \n",
    "\n",
    "            args = {'in_folder': edf_source, \n",
    "                    \"device\" : device, \n",
    "                    \"out_folder\" : edf_dest, \n",
    "                    \"file_name\" : file_name, \n",
    "                    \"radius_x\" : radius_x, \n",
    "                    \"radius_y\" : radius_y, \n",
    "                    \"sigma\" : sigma, \n",
    "                    \"xTiles\" : xSplit, \n",
    "                    \"yTiles\" : ySplit, \n",
    "                    \"z_start\" : z_start, \n",
    "                    \"z_end\" : z_end, \n",
    "                    \"GPU\" : GPU}\n",
    "\n",
    "            ij.py.run_macro(macro, args)\n",
    "\n",
    "            pbar.update(1)\n",
    "        gc.collect()\n",
    "\n",
    "pbar.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138c5fe8",
   "metadata": {},
   "source": [
    "## 6. VALIS Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f386fb",
   "metadata": {},
   "source": [
    "- Registration is performed using the VALIS program https://valis.readthedocs.io/en/stable/examples.html. \n",
    "- In the following cell, the images produced in Section 5 are combined to multi-channel tif files in a format the VALIS program is compatible with.\n",
    "- Enter the cycles being processed, the data_type desired, and the pixel size.\n",
    "- The metadata and parameters for pyramidal output may be changed.\n",
    "- Be sure the path to the vips binaries is defined correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c6a31",
   "metadata": {},
   "source": [
    "### 6.1 Combine channels for each cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_start_cycle = 1\n",
    "reg_end_cycle = 13\n",
    "data_type = \"uint16\"  \n",
    "pixel_size = float(0.377)\n",
    "\n",
    "logging.basicConfig(level=logging.WARN) #change to INFO for more details\n",
    "\n",
    "if os_system == \"Windows\":\n",
    "    vipshome = os.path.join(base_dir, 'KINTSUGI','vips-dev-8.16','bin')\n",
    "    os.environ['PATH'] = vipshome + ';' + os.environ['PATH']\n",
    "\n",
    "import pyvips \n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "os.makedirs(reg_dir, exist_ok=True)\n",
    "\n",
    "pbar_filesave = tqdm(total=100, unit=\"Percent\",\n",
    "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True)\n",
    "\n",
    "for j in range(reg_start_cycle, reg_end_cycle + 1):\n",
    "\n",
    "    cycle= f\"cyc{str(j).zfill(2)}\" \n",
    "     \n",
    "    reg_source = os.path.join(edf_dir, f\"cyc{str(j).zfill(2)}\") \n",
    "    image_set = glob(os.path.join(reg_source, '*.tif'))\n",
    "    channel_name_order = channel_name_dict.get(f\"cyc{str(j).zfill(2)}.tif\")\n",
    "    image_set.sort(key=lambda x: channel_name_order.index(os.path.basename(x).split('.')[0]))\n",
    "  \n",
    "    channel_names = []\n",
    "    for i in range(len(image_set)):\n",
    "        split_name = os.path.basename(image_set[i].split(\".\")[0])\n",
    "        channel_names.append(split_name)\n",
    " \n",
    "    pyvips_image_set = [pyvips.Image.new_from_file(os.path.join(reg_source, filename), access=\"sequential\") for filename in image_set]\n",
    "\n",
    "    out_init = pyvips.Image.arrayjoin(pyvips_image_set, across=1)\n",
    "    out = out_init.copy()\n",
    "    out.set_type(pyvips.GValue.gint_type, \"page-height\", pyvips_image_set[0].height)\n",
    "\n",
    "    x_dim = pyvips_image_set[0].width\n",
    "    y_dim = pyvips_image_set[0].height\n",
    "\n",
    "    bands = len(pyvips_image_set)\n",
    "    outfile = os.path.join(reg_dir, f'cyc{str(j).zfill(2)}.ome.tif')\n",
    "    out.set_type(pyvips.GValue.gstr_type, \"image-description\",\n",
    "    f\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "        <OME xmlns=\"http://www.openmicroscopy.org/Schemas/OME/2016-06\"\n",
    "            xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "            xsi:schemaLocation=\"http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd\">\n",
    "            <Image ID=\"Image:0\" Name=\"{cycle}\" >\n",
    "                <!-- Minimum required fields about image dimensions -->\n",
    "                <Pixels BigEndian=\"false\"\n",
    "                        DimensionOrder=\"XYCZT\" \n",
    "                        ID=\"Pixels:0\"\n",
    "                        Interleaved=\"false\"\n",
    "                        SignificantBits=\"16\"                                              \n",
    "                        SizeC=\"{bands}\" \n",
    "                        SizeT=\"1\" \n",
    "                        SizeX=\"{x_dim}\" \n",
    "                        SizeY=\"{y_dim}\" \n",
    "                        SizeZ=\"1\" \n",
    "                        Type=\"{data_type}\" \n",
    "                        PhysicalSizeX=\"{pixel_size}\" \n",
    "                        PhysicalSizeY=\"{pixel_size}\">\n",
    "                    <TiffData FirstC=\"0\" FirstT=\"0\" FirstZ=\"0\" IFD=\"0\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"16751615\" ID=\"Channel:0:0\" Name=\"{channel_names[0]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"1\" FirstT=\"0\" FirstZ=\"0\" IFD=\"1\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"7995391\" ID=\"Channel:0:1\" Name=\"{channel_names[1]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"2\" FirstT=\"0\" FirstZ=\"0\" IFD=\"2\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"9043967\" ID=\"Channel:0:2\" Name=\"{channel_names[2]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                    <TiffData FirstC=\"3\" FirstT=\"0\" FirstZ=\"0\" IFD=\"3\" PlaneCount=\"1\"/>\n",
    "                    <Channel Color=\"1828651263\" ID=\"Channel:0:3\" Name=\"{channel_names[3]}\" IlluminationType=\"Epifluorescence\" ContrastMethod=\"Fluorescence\" AcquisitionMode=\"WideField\" SamplesPerPixel=\"1\"/>\n",
    "                </Pixels>\n",
    "            </Image>\n",
    "        </OME>\"\"\")\n",
    "\n",
    "    out.tiffsave(outfile, subifd=True, page_height=y_dim, compression='lzw', tile=True,\n",
    "                  tile_width=512, tile_height=512, pyramid=True, bigtiff=True)\n",
    "    out_init = None\n",
    "    out = None\n",
    "    pyvips_image_set = None\n",
    "    gc.collect() \n",
    "    pbar_filesave.update(100 / (reg_end_cycle - reg_start_cycle + 1))\n",
    "\n",
    "pbar_filesave.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3abfed",
   "metadata": {},
   "source": [
    "### 6.2 Standard Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc26d2",
   "metadata": {},
   "source": [
    "- See https://github.com/MathOnco/valis/tree/main for full documentation. \n",
    "The process for registration involves producing registration data on the rigid and non-rigid movement of the images relative to one another to bring about alignment as they overlap.  Because writing of the registered images takes a long time, it is advisable to use the registration data rather than the images themselves to assess registration.  There is an optional micro-registration if smaller structure overlap is important.  Either way, the registration results to be used for the image registration is stored in the results_dst_dir as a .pickle file.\n",
    "- According to the VALIS docs: One of the most important parameters used to initialize a Valis object is max_processed_image_dim_px, which determines the size of the image used to find the rigid registration parameters. The default value is 850, but if registration fails or is poor, try adjusting that value. Generally speaking, values between 500-2000 work well. In cases where there is little empty space around the tissue, smaller values may be better. However, if there is a large amount of empty space/slide (as in the images above), larger values may be needed so that the tissue is at a high enough resolution. To improve alignment of the finer details in the images, larger images can be used in the non-rigid or micro-registration steps (set via the max_non_rigid_registration_dim_px parameter).\n",
    "- If you get an error that the jvm is not found, try uncommenting the registration.init_jvm() line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d56ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_system = platform.system()\n",
    "if os_system == \"Windows\":\n",
    "    vipsbin = os.path.join(base_dir, 'KINTSUGI','vips-dev-8.16','bin')\n",
    "    os.environ['PATH'] = vipsbin + ';' + os.environ['PATH']\n",
    "javahome = os.path.join(base_dir, \"KINTSUGI\", \"jdk-21_windows-x64_bin\", \"jdk-21.0.5\", \"bin\")\n",
    "os.environ['PATH'] = javahome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "mavenhome = os.path.join(base_dir, 'KINTSUGI','apache-maven-3.9.9-bin','apache-maven-3.9.9', 'bin')\n",
    "os.environ['PATH'] = mavenhome + os.pathsep + os.environ['PATH']\n",
    "\n",
    "from Kreg import registration\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 2000000000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# registration.init_jvm()\n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "\n",
    "slide_src_dir = reg_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345b551",
   "metadata": {},
   "source": [
    "- There are two methods of choosing the target image that all other images will be aligned to.  The default is to register \"towards\" the center image.  The other is to choose a \"reference_slide.\"  If choosing a reference_slide, you must add the image name and reference_img_f=reference_slide to registration.Valis.  If you are then adding micro registration, you must add align_to_reference=True.\n",
    "- Running this cell will produce registration data, but will not register the images, allowing for testing different parameters.\n",
    "- Note that if you rerun the registration, results will be overwritten.  To avoid this you will need to rename your results_dst_dir folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f08fb17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\smith6jt\\KINTSUGI\\notebooks\\Kreg\\valtils.py:25: UserWarning: max_image_dim_px is 1024 but needs to be less or equal to 1200. Setting max_image_dim_px to 1200\n",
      "  warnings.warn(warning_msg, warning_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Converting images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:   0%|          | 0/13 [00:00<?, ?image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc01>, width=9962, height=9484, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x000001970A180BB0> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:   8%|▊         | 1/13 [00:01<00:16,  1.39s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc02>, width=9964, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x0000019714654E50> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  15%|█▌        | 2/13 [00:02<00:14,  1.36s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc03>, width=9960, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x0000019714871C70> False (1143, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  23%|██▎       | 3/13 [00:04<00:13,  1.34s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc04>, width=9960, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179D51F0> False (1143, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  31%|███       | 4/13 [00:05<00:12,  1.35s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc05>, width=9961, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x0000019714871A60> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  38%|███▊      | 5/13 [00:06<00:10,  1.27s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc06>, width=9962, height=9488, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x0000019714871700> False (1143, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  46%|████▌     | 6/13 [00:07<00:08,  1.26s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc07>, width=9962, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179B1F40> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  54%|█████▍    | 7/13 [00:08<00:07,  1.23s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc08>, width=9960, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179D58B0> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  62%|██████▏   | 8/13 [00:10<00:06,  1.22s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc09>, width=9964, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179F2A60> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  69%|██████▉   | 9/13 [00:11<00:04,  1.19s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc10>, width=9963, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179B1700> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  77%|███████▋  | 10/13 [00:12<00:03,  1.19s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc11>, width=9960, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197148599D0> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  85%|████████▍ | 11/13 [00:13<00:02,  1.22s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc12>, width=9962, height=9486, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x0000019722E2DE20> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images:  92%|█████████▏| 12/13 [00:15<00:01,  1.24s/image]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Slide, name = cyc13>, width=9963, height=9487, channels=4, levels=6, RGB=False, dtype=uint16> <Kreg.slide_io.VipsSlideReader object at 0x00000197179B1FD0> False (1142, 1200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting images: 100%|██████████| 13/13 [00:16<00:00,  1.26s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processing images\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images : 100%|██████████| 13/13 [00:20<00:00,  1.61s/image]\n",
      "Normalizing images: 100%|██████████| 13/13 [00:02<00:00,  5.99image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Rigid registration\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting features   : 100%|██████████| 13/13 [00:13<00:00,  1.04s/image]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a075673672874403b2e6b48bf9e2677c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0947c9c9c5c84507bff59454a1f5e579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794999d433644698a58c461de5a0ed7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | Matching images      :   0%|          | 0/13 [00:00<?, ?image/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding transforms   : 100%|██████████| 12/12 [00:00<00:00, 768.05image/s]\n",
      "Finalizing           : 100%|██████████| 13/13 [00:00<?, ?image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Rigid registration complete in 37.036 seconds\n",
      "\n",
      "\n",
      "==== Non-rigid registration\n",
      "\n",
      "Creating non-rigid mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing images for non-rigid registration: 100%|██████████| 13/13 [00:14<00:00,  1.11s/image]\n",
      "Finding non-rigid transforms: 100%|██████████| 13/13 [02:08<00:00,  9.92s/image]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Non-rigid registration complete in 2.156 minutes\n",
      "\n",
      "\n",
      "==== Measuring error\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring error: 100%|██████████| 13/13 [00:04<00:00,  2.72image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM has been killed. If this was due to an error, then a new Python session will need to be started\n"
     ]
    }
   ],
   "source": [
    "from Kreg import feature_detectors\n",
    "\n",
    "reference_slide = \"cyc02.ome.tif\"\n",
    "# reference_slide = None\n",
    "align_to_reference = True\n",
    "crop = \"reference\"\n",
    "compose_non_rigid = True\n",
    "feature_detector_cls = feature_detectors.OrbVggFD\n",
    "create_masks=False\n",
    "imgs_ordered = True\n",
    "results_dst_dir = os.path.join(reg_dir, \"valis_out_standard\")\n",
    "max_processed_image_dim_px = 1200\n",
    "max_image_dim_px = max_processed_image_dim_px\n",
    "\n",
    "registrar = registration.Valis(src_dir=slide_src_dir, dst_dir=results_dst_dir, crop=crop, imgs_ordered=imgs_ordered, max_processed_image_dim_px=max_processed_image_dim_px, compose_non_rigid=compose_non_rigid, align_to_reference=align_to_reference, reference_img_f=reference_slide, feature_detector_cls=feature_detector_cls, create_masks=create_masks, max_image_dim_px=max_image_dim_px)\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ec5c5",
   "metadata": {},
   "source": [
    "- Review the results in the produced registration folder saved in “valis_out_standard”\n",
    "- A quick method is to scroll through the “non_rigid_registration” images below.  While scrolling through the images with the slider, there should be no movement of the pixels except between  the reference image and the image next to the reference.  Other options to view by replacing \"non_rigid_registration\" below: \"masks\", \"deformation_fields\", and \"rigid_registration\".\n",
    "- To view the output, you may need to click the ellipses next to the output cell and click \"Change Presentation\" to choose IPyWidgetRenderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56b4430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6855080d04fd5b936c98664321af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=799, width=840),…"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other options to view by replacing \"non_rigid_registration\" below: \"masks\", \"deformation_fields\",  and \"rigid_registration\".\n",
    "im_raw_deform = glob(os.path.join(reg_dir, \"valis_out_standard\", os.path.basename(reg_dir), \"non_rigid_registration\", \"*.png\"))\n",
    "im_deform = imread_collection(im_raw_deform)\n",
    "deform = np.asarray(im_deform).astype(np.uint8)\n",
    "\n",
    "stackview.slice(deform, zoom_factor=0.7, continuous_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87676b5",
   "metadata": {},
   "source": [
    "### 6.3 Micro Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024707a",
   "metadata": {},
   "source": [
    "- For DAPI only image sets, micro registration is generally not needed.\n",
    "- If further refining of results is warranted, the optional micro-registration may be used as a new registration or as a refinement of the first.\n",
    "- Micro-registration as the first registration takes much longer (e.g. standard ~5-10 min and micro ~2-3 hrs) than standard registration.  Be sure to test a few changes to the standard method before switching to micro.\n",
    "- A faster method of micro-registration is to perform standard first and then a second non-rigid registration using \"register_micro\" in the cell below the MicroRigidRegistrar import.\n",
    "- Note that the previous registration is saved to the .pickle file in path_to_register.  This will be overwritten by the micro-registration results.  To avoid this, rename the .pickle file.\n",
    "- The cell below determines the parameter to use based on 25% of original resolution.  The reasoning behind using 25% is unknown, but suggested in the VALIS documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68de6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro registration size: 2490\n"
     ]
    }
   ],
   "source": [
    "micro_reg_fraction = 0.25\n",
    "path_to_registrar = os.path.join(reg_dir, \"valis_out_standard\", os.path.basename(reg_dir),\"data\", os.path.basename(reg_dir)+\"_registrar.pickle\")\n",
    "registrar = registration.load_registrar(path_to_registrar)\n",
    "img_dims = np.array([slide_obj.slide_dimensions_wh[0] for slide_obj in registrar.slide_dict.values()])\n",
    "min_max_size = np.min([np.max(d) for d in img_dims])\n",
    "img_areas = [np.multiply(*d) for d in img_dims]\n",
    "max_img_w, max_img_h = tuple(img_dims[np.argmax(img_areas)])\n",
    "micro_reg_size = np.floor(min_max_size*micro_reg_fraction).astype(int)\n",
    "print(f\"Micro registration size: {micro_reg_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from valis.micro_rigid_registrar import MicroRigidRegistrar\n",
    "\n",
    "micro_results_dst_dir = os.path.join(reg_dir, \"valis_out_micro\")\n",
    "registrar = registration.Valis(slide_src_dir, micro_results_dst_dir, micro_rigid_registrar_cls=MicroRigidRegistrar)\n",
    "rigid_registrar, non_rigid_registrar, error_df = registrar.register()\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d823a39",
   "metadata": {},
   "source": [
    "Uncommenting the \"matches_dst_dir\" lines below will enable output of images showing colored lines between the matching points of the images.  Sometimes there are so many that interpretation is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c79452",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_slide = \"cyc02.ome.tif\"\n",
    "# reference_slide = None\n",
    "align_to_reference = True\n",
    "if_processing_kwargs = {\"channel\": \"DAPI\", \"adaptive_eq\": True}\n",
    "\n",
    "micro_reg, micro_error = registrar.register_micro(max_non_rigid_registration_dim_px=micro_reg_size, align_to_reference=align_to_reference, reference_img_f=reference_slide,  if_processing_kwargs=if_processing_kwargs)\n",
    "# matches_dst_dir = os.path.join(registrar.dst_dir, \"hi_rez_matches\")\n",
    "# registrar.draw_matches(matches_dst_dir)\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c190f53",
   "metadata": {},
   "source": [
    "- Review the results of micro-registration.\n",
    "- New output will be for \"micro_registration\", \"overlaps\", and \"hi_rez_matches\" if enabled.  Note \"overlaps\" will be images of different shapes and cannot be viewed with stackview.slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"micro_registration\", \"overlaps\", and possibly \"hi_rez_matches\"\n",
    "im_raw_micro = glob(os.path.join(reg_dir, \"valis_out_standard\", os.path.basename(reg_dir), \"micro_registration\", \"*.png\"))\n",
    "im_micro = imread_collection(im_raw_micro)\n",
    "micro = np.asarray(im_micro).astype(np.uint8)\n",
    "\n",
    "stackview.slice(micro, zoom_factor=0.7, continuous_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e6050",
   "metadata": {},
   "source": [
    "### 6.4 Warp and Save Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c8b01",
   "metadata": {},
   "source": [
    "Here is where the application of the registration to the images occurs.  The first cell merges all images to one file, while the second creates one image per cycle. If multiple rounds of testing was done, be sure you are using the final .pickle file for the final image creation.\n",
    "- At this point, images are likely not the same size.  Using the crop function will crop all images to the same size.  This is necessary to use image math functions in the next notebook.\n",
    "- Naming is based on the definitions of “channel_name_dict” defined above.  It may be necessary to run that cell again.\n",
    "- The registration of the common first channel will effectively align the rest of the channels in each cycle to one another.\n",
    "- Note that writting large image files generally takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a3e78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name_dict = {\"cyc01.ome.tif\" : [\"DAPI\", \"Blank1a\", \"Blank1b\", \"Blank1c\"],\n",
    " \"cyc02.ome.tif\" : [\"DAPI\", \"CD31\", \"CD8\", \"Empty2c\"],\n",
    " \"cyc03.ome.tif\" : [\"DAPI\", \"CD20\", \"Ki67\", \"CD3e\"],\n",
    " \"cyc04.ome.tif\" : [\"DAPI\", \"SMActin\", \"Podoplanin\", \"CD68\"],\n",
    " \"cyc05.ome.tif\" : [\"DAPI\", \"PanCK\", \"CD21\", \"CD4\"],\n",
    " \"cyc06.ome.tif\" : [\"DAPI\", \"Lyve1\", \"CD45RO\", \"CD11c\"],\n",
    " \"cyc07.ome.tif\" : [\"DAPI\", \"CD35\", \"ECAD\", \"CD107a\"],\n",
    " \"cyc08.ome.tif\" : [\"DAPI\", \"CD34\", \"CD44\", \"HLADR\"],\n",
    " \"cyc09.ome.tif\" : [\"DAPI\", \"Empty9a\", \"FoxP3\", \"CD163\"],\n",
    " \"cyc10.ome.tif\" : [\"DAPI\", \"Empty10a\", \"CollagenIV\", \"Vimentin\"],\n",
    " \"cyc11.ome.tif\" : [\"DAPI\", \"Empty11a\", \"CD15\", \"CD45\"],\n",
    " \"cyc12.ome.tif\" : [\"DAPI\", \"Empty12a\", \"CD5\", \"CD1c\"],\n",
    " \"cyc13.ome.tif\" : [\"DAPI\", \"Blank13a\", \"Blank13b\", \"Blank13c\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50e35b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc03.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.341 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc04.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.282 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc05.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 3.993 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc06.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.027 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc07.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.159 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc08.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.111 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc09.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.115 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc10.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 3.895 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc11.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 3.996 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc12.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 4.098 minutes\n",
      "Complete\n",
      "\n",
      "saving C:\\Users\\smith6jt\\KINTSUGI\\data\\1904_CC2B_Registration\\registered\\cyc13.ome.tif (9964 x 9486 and 4 channels)\n",
      "\n",
      "[====================================================================================================] 100.0% in 3.98 minutes\n",
      "Complete\n",
      "\n",
      "JVM has been killed. If this was due to an error, then a new Python session will need to be started\n"
     ]
    }
   ],
   "source": [
    "path_to_registrar = os.path.join(reg_dir, \"valis_out_standard\", os.path.basename(reg_dir),\"data\", os.path.basename(reg_dir)+\"_registrar.pickle\")\n",
    "registrar = registration.load_registrar(path_to_registrar)\n",
    "reg_dir_out = os.path.join(reg_dir, \"registered\")\n",
    "os.makedirs(reg_dir_out, exist_ok=True)\n",
    "\n",
    "first = 3\n",
    "last = 13\n",
    "\n",
    "for slide_name, slide_obj in registrar.slide_dict.items():\n",
    "    for i in range(first, last +1):\n",
    "        if slide_name == f\"cyc{str(i).zfill(2)}\":\n",
    "\n",
    "            dst_f = os.path.join(reg_dir_out, f\"{slide_name}.ome.tif\")\n",
    "            slide_obj.warp_and_save_slide(dst_f=dst_f, \n",
    "                                        crop=\"reference\",\n",
    "                                        channel_names=channel_name_dict.get(slide_name),\n",
    "                                        level=0, \n",
    "                                        compression=\"lzw\",\n",
    "                                        tile_wh=2048,\n",
    "                                        pyramid=False)\n",
    "\n",
    "registration.kill_jvm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaf7f2f",
   "metadata": {},
   "source": [
    "### 6.5 Compare Registered to Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d496c58",
   "metadata": {},
   "source": [
    "- Read in two images from the original dataset.\n",
    "- Enter crop coordinates.\n",
    "- The slider will change channels.\n",
    "- Read in the same two images from the registered dataset.\n",
    "- Magenta and green should be white/grey when perfectly overlapped.  Registration deviation will show as magenta or green offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f67c05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (4, 9484, 9962). Output image shape: (4, 9486, 9964)\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "\n",
    "edf_dir = stitch_dir.replace('_BaSiC_Stitched', '_EDF')\n",
    "reg_dir = edf_dir.replace('_EDF', '_Registration')\n",
    "orig_a = os.path.join(reg_dir, \"cyc01.ome.tif\")\n",
    "orig_a = tifffile.imread(orig_a)\n",
    "\n",
    "orig_b = os.path.join(reg_dir, \"cyc02.ome.tif\")\n",
    "orig_b = tifffile.imread(orig_b)\n",
    "\n",
    "print(f\"Input image shape: {orig_a.shape}. Output image shape: {orig_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d677aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side_by_side\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf1adce5d764d1f9afc56d6d86dca92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(HBox(children=(VBox(children=(ImageWidget(height=8…"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 7000\n",
    "x2 = 7500\n",
    "y1 = 8000\n",
    "y2 = 8500\n",
    "\n",
    "a = orig_a[:, y1:y2, x1:x2]\n",
    "b = orig_b[:, y1:y2, x1:x2]\n",
    "\n",
    "stackview.side_by_side(a, b, zoom_factor=1.6, continuous_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "312aa13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: (4, 9486, 9964). Output image shape: (4, 9486, 9964)\n"
     ]
    }
   ],
   "source": [
    "reg_a = os.path.join(reg_dir, \"registered\", \"cyc01.ome.tif\")\n",
    "reg_a = tifffile.imread(reg_a)\n",
    "\n",
    "reg_b = os.path.join(reg_dir, \"registered\", \"cyc02.ome.tif\")\n",
    "reg_b = tifffile.imread(reg_b)\n",
    "\n",
    "print(f\"Input image shape: {reg_a.shape}. Output image shape: {reg_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3c85530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side_by_side\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7539ab94414b06a3ca25956eba70e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(HBox(children=(VBox(children=(ImageWidget(height=8…"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 7000\n",
    "x2 = 7500\n",
    "y1 = 8000\n",
    "y2 = 8500\n",
    "\n",
    "ra = reg_a[:, y1:y2, x1:x2]\n",
    "rb = reg_b[:, y1:y2, x1:x2]\n",
    "\n",
    "stackview.side_by_side(ra, rb, zoom_factor=1.6, continuous_update=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KINTSUGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
