{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Cluster pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following notebook you will begin the process of phenotyping cells by using a self-organizing map algorithm to cluster the pixels.  This is the \"Pixie\" project from the ark-analysis repo https://github.com/angelolab/ark-analysis/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages. \n",
    "### *This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:04:37.131203Z",
     "iopub.status.busy": "2024-11-14T23:04:37.130617Z",
     "iopub.status.idle": "2024-11-14T23:04:38.998613Z",
     "shell.execute_reply": "2024-11-14T23:04:38.998336Z",
     "shell.execute_reply.started": "2024-11-14T23:04:37.131187Z"
    },
    "tags": [
     "import"
    ]
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "from alpineer import io_utils, load_utils\n",
    "from matplotlib import rc_file_defaults\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyFlowSOM\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tifffile import imread\n",
    "from tqdm.notebook import tqdm\n",
    "import stackview\n",
    "\n",
    "from ark.phenotyping import (pixel_cluster_utils, pixel_meta_clustering,\n",
    "                             pixel_som_clustering, pixie_preprocessing)\n",
    "from ark.utils import data_utils\n",
    "from ark.utils import plot_utils\n",
    "from ark.utils.metacluster_remap_gui import (MetaClusterGui,\n",
    "                                             colormap_helper,\n",
    "                                             metaclusterdata_from_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define directory paths. \n",
    "### *This must be done every time the notebook is started or restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation folder is C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_Segmentation.\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/Users/smith6jt/KINTSUGI/data/1904_CC2B_Segmentation\"\n",
    "print(f\"Segmentation folder is {base_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tiff_dir`: path to the directory containing your imaging data. Images should be single-channel TIFFs.\n",
    "* `img_sub_folder`: if `tiff_dir` contains an additional subfolder structure, override `None` with the appropriate folder name\n",
    "* `segmentation_dir`: path to the directory containing your segmentations (which can be generated using `1_Segment_Image_Data.ipynb`). Set this argument to `None` if you do not have segmentation labels or wish to run pixel clustering without them (they are required for cell clustering)\n",
    "* `seg_suffix`: the suffix plus the file extension of the segmented images for each FOV. Note that these should be the same for all FOVs. This argument will be ignored if `segmentation_dir` is set to `None`\n",
    "* `pixie_seg_dir`: the created path from the `segmentation_dir`. Is `None` if `segmentation_dir` is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:04:43.518731Z",
     "iopub.status.busy": "2024-11-14T23:04:43.518549Z",
     "iopub.status.idle": "2024-11-14T23:04:43.521105Z",
     "shell.execute_reply": "2024-11-14T23:04:43.520832Z",
     "shell.execute_reply.started": "2024-11-14T23:04:43.518720Z"
    },
    "tags": [
     "file_path"
    ]
   },
   "outputs": [],
   "source": [
    "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
    "img_sub_folder = None\n",
    "segmentation_dir = os.path.join(\"segmentation\", \"deepcell_output\")\n",
    "seg_suffix = '_whole_cell.tiff'\n",
    "\n",
    "if segmentation_dir is not None:\n",
    "    pixie_seg_dir = os.path.join(base_dir, segmentation_dir)\n",
    "else:\n",
    "    pixie_seg_dir = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `fovs` (optional): set a specific set of fovs to load, default loads all the fovs in `tiff_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:04:49.478783Z",
     "iopub.status.busy": "2024-11-14T23:04:49.478593Z",
     "iopub.status.idle": "2024-11-14T23:04:49.481661Z",
     "shell.execute_reply": "2024-11-14T23:04:49.481400Z",
     "shell.execute_reply.started": "2024-11-14T23:04:49.478772Z"
    },
    "tags": [
     "load_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# either get all fovs in the folder...\n",
    "fovs = io_utils.list_folders(tiff_dir)\n",
    "\n",
    "# ... or optionally, select a specific set of fovs manually\n",
    "# fovs = [\"fov14\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define multiprocessing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning on multiprocessing provides a speed boost; however, it is not always cross-platform compatible. If you receive errors such as hanging cells without progress updates, try setting `multiprocess` back to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:04:56.159099Z",
     "iopub.status.busy": "2024-11-14T23:04:56.158929Z",
     "iopub.status.idle": "2024-11-14T23:04:56.161067Z",
     "shell.execute_reply": "2024-11-14T23:04:56.160802Z",
     "shell.execute_reply.started": "2024-11-14T23:04:56.159086Z"
    },
    "tags": [
     "set_multi"
    ]
   },
   "outputs": [],
   "source": [
    "# set to True to turn on multiprocessing\n",
    "multiprocess = True\n",
    "\n",
    "# define the number of FOVs to process in parallel, ignored if multiprocessing is set to False\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a prefix to be applied to all data directories/files created during pixel clustering. If the prefix is not set, a default of the datetime at the start of the run is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:05:05.970816Z",
     "iopub.status.busy": "2024-11-14T23:05:05.970620Z",
     "iopub.status.idle": "2024-11-14T23:05:05.973027Z",
     "shell.execute_reply": "2024-11-14T23:05:05.972696Z",
     "shell.execute_reply.started": "2024-11-14T23:05:05.970802Z"
    },
    "tags": [
     "pixel_prefix"
    ]
   },
   "outputs": [],
   "source": [
    "# explicitly set pixel_cluster_prefix to override datetime default\n",
    "pixel_cluster_prefix = \"1904CC2B28\"\n",
    "\n",
    "if pixel_cluster_prefix is None:\n",
    "    pixel_cluster_prefix = dt.now().strftime('%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data directories/files will be created with names prefixed by `pixel_cluster_prefix`:\n",
    "\n",
    "* `pixel_output_dir`: directory name where the pixel clustering outputs are stored\n",
    "* `preprocessed_dir`: directory name where the preprocessed pixel data are stored\n",
    "* `subsetted_dir`: directory name where the subsetted pixel data are stored\n",
    "* `norm_vals_name`: file name where the values used to normalize each channel are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:05:45.196250Z",
     "iopub.status.busy": "2024-11-14T23:05:45.196073Z",
     "iopub.status.idle": "2024-11-14T23:05:45.198791Z",
     "shell.execute_reply": "2024-11-14T23:05:45.198527Z",
     "shell.execute_reply.started": "2024-11-14T23:05:45.196238Z"
    },
    "tags": [
     "dir_set"
    ]
   },
   "outputs": [],
   "source": [
    "# define the output directory using the specified pixel cluster prefix\n",
    "pixel_output_dir = os.path.join(\"pixie\", \"%s_pixel_output_dir\" % pixel_cluster_prefix)\n",
    "if not os.path.exists(os.path.join(base_dir, pixel_output_dir)):\n",
    "    os.makedirs(os.path.join(base_dir, pixel_output_dir))\n",
    "\n",
    "# define the preprocessed pixel data folders\n",
    "pixel_data_dir = os.path.join(pixel_output_dir, 'pixel_mat_data')\n",
    "pixel_subset_dir = os.path.join(pixel_output_dir, 'pixel_mat_subset')\n",
    "norm_vals_name = os.path.join(pixel_output_dir, 'channel_norm_post_rownorm.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Blurring and masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For certain channels, such as membraneous tumor markers, the subcellular localization of the marker isn't important. Instead, what matters is that cells which are positive for the marker show up as positive. In these cases, we have sometimes found it useful to add additional blurring to these markers before clustering. This ensures that more of the pixels within the cell are positive for the marker, instead of only a few pixels at the border, especially for cells which are under-segmented. However, higher blur levels will also cause more of the pixels in neighboring cells to show up as positive. Therefore, this works best when you have other, robust markers (like CD45) which you can use to determine which cells are false positives for the blurred channel. If you have markers in your panel which fit this description, you can add them in the cell below. Then, when specifying the list of markers to include for clustering, make sure to add `{marker_name}_smoothed`, as that is what the TIFF will be called.\n",
    "\n",
    "Skip this cell if you don't want to add an additional blur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "smooth_channels"
    ]
   },
   "outputs": [],
   "source": [
    "# set an optional list of markers for additional blurring\n",
    "\n",
    "blurred_channels = [\"Vimentin\"]\n",
    "smooth_vals = 3\n",
    "\n",
    "pixel_cluster_utils.smooth_channels(\n",
    "    fovs=fovs,\n",
    "    tiff_dir=tiff_dir,\n",
    "    img_sub_folder=img_sub_folder,\n",
    "    channels=blurred_channels,\n",
    "    smooth_vals=smooth_vals,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, markers will have background staining that you'll want to filter out for the clustering process. Define the name of the marker you want to filter using `filter_channel`. If the marker is only present in the nucleus, set `exclude = False` to filter it out from the membrane. Conversely, if the marker is only present in the membrane, set `exclude = True` to filter it out from the nucleus.\n",
    "\n",
    "When specifying the list of markers to include for clustering, make sure to add `{marker_name}_nuc_exclude` or `{marker_name}_nuc_include` depending on what type of signal was filtered out.\n",
    "\n",
    "Skip this cell if you don't want to run marker filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_channel = 'Ki67'\n",
    "nuclear_exclude = False\n",
    "\n",
    "pixel_cluster_utils.filter_with_nuclear(\n",
    "    fovs=fovs,\n",
    "    tiff_dir=tiff_dir,\n",
    "    seg_dir=os.path.join(base_dir, segmentation_dir),\n",
    "    channel=filter_channel,\n",
    "    nuc_seg_suffix=\"_nuclear.tiff\",\n",
    "    exclude=nuclear_exclude\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following arguments:\n",
    "\n",
    "* `channels`: channels to run pixel clustering on\n",
    "* `blur_factor`: sigma (standard deviation) for the Gaussian blur. Higher values are more aggressive in smoothing signal.\n",
    "* `subset_proportion`: the fraction of pixels to take from each FOV for training. Sampling is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:14:41.202671Z",
     "iopub.status.busy": "2024-11-14T23:14:41.202495Z",
     "iopub.status.idle": "2024-11-14T23:14:41.205040Z",
     "shell.execute_reply": "2024-11-14T23:14:41.204709Z",
     "shell.execute_reply.started": "2024-11-14T23:14:41.202658Z"
    },
    "tags": [
     "channel_set"
    ]
   },
   "outputs": [],
   "source": [
    "channels = ['CD4', 'CD8', 'SMActin', 'CD3e']\n",
    "blur_factor = 0\n",
    "subset_proportion = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During pixel preprocessing, the following is done for each FOV:\n",
    "\n",
    "* Gaussian blur each channel separately\n",
    "* Remove empty pixels\n",
    "* For the remaining pixels, normalize each pixel by the sum of all the channels\n",
    "* Subset a `subset_proportion` fraction of non-empty, normalized pixels. This creates the subsetted dataset for training\n",
    "\n",
    "Note: if you get integer overflow errors loading in your data, try changing the `dtype` argument to a larger type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:14:42.438405Z",
     "iopub.status.busy": "2024-11-14T23:14:42.438241Z",
     "iopub.status.idle": "2024-11-14T23:25:49.136136Z",
     "shell.execute_reply": "2024-11-14T23:25:49.135656Z",
     "shell.execute_reply.started": "2024-11-14T23:14:42.438394Z"
    },
    "tags": [
     "gen_pixel_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# run pixel data preprocessing\n",
    "pixie_preprocessing.create_pixel_matrix(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    tiff_dir,\n",
    "    pixie_seg_dir,\n",
    "    img_sub_folder=img_sub_folder,\n",
    "    seg_suffix=seg_suffix,\n",
    "    pixel_output_dir=pixel_output_dir,\n",
    "    data_dir=pixel_data_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name_post_rownorm=norm_vals_name,\n",
    "    blur_factor=blur_factor,\n",
    "    subset_proportion=subset_proportion,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pixel clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Visualize pixel SOM performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test parameters:  Choose fov and channel to visualize, channels to include, number of nodes (this will be xdim x ydim), and the number of training epochs (num_passes).  The learning rates are a more advanced parameter.  Seed is kept constant if reproducible results are important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_som_training(fov_file: str, \n",
    "                         channels: list,\n",
    "                         channel_vis: str,\n",
    "                         xdim: int = 10, \n",
    "                         ydim: int = 10,\n",
    "                         num_passes: int = 5,\n",
    "                         lr_start: float = 0.05,\n",
    "                         lr_end: float = 0.01,\n",
    "                         show_plots: bool = False):\n",
    "\n",
    "    pixel_data = pd.read_feather(fov_file)\n",
    "    train_data = pixel_data[channels].values.astype(np.float64)\n",
    "    num_nodes = xdim * ydim\n",
    "    image = imread(os.path.join(tiff_dir, \"fov1\", channel_vis+\".tif\"))\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, num_nodes))\n",
    "    node_cmap = ListedColormap(colors)\n",
    "\n",
    "    pbar_filesave = tqdm(total=100, unit=\"Percent\",\n",
    "                    bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]',\n",
    "                    colour=\"green\", position=0, leave=True)\n",
    "\n",
    "    scatter_frames = []\n",
    "    for rlen_iter in range(1, num_passes + 1):\n",
    "        # print(f\"Training for rlen={rlen_iter}\")\n",
    "        som = pyFlowSOM.som(train_data, xdim, ydim, rlen_iter, alpha_range=(lr_start, lr_end), seed=42)\n",
    "        clusters, dist = pyFlowSOM.map_data_to_nodes(som, train_data)\n",
    "\n",
    "        pixel_data['cluster'] = clusters\n",
    "        df_mean = pixel_data.groupby(['cluster']).mean()\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(21, 7))\n",
    "        im = axes[0].imshow(image, vmax=np.percentile(image, 99.9), cmap='gray')\n",
    "        fig.colorbar(im, shrink=0.5, ax=axes[0], cmap=node_cmap)\n",
    "        axes[0].set_title(f'Original Image: {channel_vis}')\n",
    "        im = axes[1].scatter(pixel_data['column_index'], pixel_data['row_index'], \n",
    "                                c=pixel_data['cluster'],\n",
    "                                cmap=node_cmap, s=1)\n",
    "        axes[1].invert_yaxis()\n",
    "        axes[1].set_aspect(image.shape[1] / image.shape[0])\n",
    "        axes[1].set_title(f'SOM Iteration {rlen_iter}')\n",
    "        fig.colorbar(im, shrink=0.5, ax=axes[1], cmap=node_cmap)\n",
    "        axes[1].set_title(f\"SOM Visualization for rlen=(rlen={rlen_iter})\")\n",
    "\n",
    "        g=sns.clustermap(df_mean, z_score=1, cmap=\"vlag\", center=0, \n",
    "                        yticklabels=True, cbar=node_cmap)\n",
    "        heatmap_data = g.data2d\n",
    "        plt.close(g.figure)\n",
    "        im = sns.heatmap(data=heatmap_data, \n",
    "                ax=axes[2],\n",
    "                cmap=\"vlag\",\n",
    "                center=0,\n",
    "                xticklabels=g.data2d.columns,\n",
    "                yticklabels=g.data2d.index)\n",
    "        \n",
    "        axes[2].set_aspect(image.shape[1] / image.shape[0])\n",
    "        axes[2].set_title(f'Cluster heatmap for rlen={rlen_iter}')\n",
    "        \n",
    "        # plt.setp(axes[2].get_xticklabels(), rotation=120)\n",
    "        # plt.setp(axes[2].get_yticklabels(), rotation=45)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        canvas = fig.canvas\n",
    "        canvas.draw()\n",
    "        width, height = fig.get_size_inches() * fig.dpi\n",
    "        buf = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n",
    "        buf.shape = (int(height), int(width), 4)\n",
    "        scatter_frame = buf[:, :, :3]\n",
    "        \n",
    "        scatter_frames.append(scatter_frame)\n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        plt.close(fig)\n",
    "        pbar_filesave.update(100 / (num_passes))\n",
    "\n",
    "    pbar_filesave.close()\n",
    "    scatter_stack = np.stack(scatter_frames, axis=0)\n",
    "    return scatter_stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67104135a574cd182fbd0c1a19ab3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabb6c5125ec45f1a7cfa617a6b9ebb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(VBox(children=(ImageWidget(height=700, width=2100)…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fov_vis = 'fov1'\n",
    "channel_vis = 'CD4'\n",
    "channels = ['CD4', 'CD8', 'SMActin', 'CD3e']\n",
    "xdim = 5\n",
    "ydim = 5\n",
    "num_passes = 10\n",
    "lr_start = 0.05\n",
    "lr_end = 0.01\n",
    "fov_file=os.path.join(base_dir, pixel_subset_dir, fov_vis+'.feather')\n",
    "\n",
    "stack = visualize_som_training(\n",
    "    fov_file=fov_file,\n",
    "    channels=channels,\n",
    "    channel_vis = channel_vis,\n",
    "    xdim=xdim,\n",
    "    ydim=ydim,\n",
    "    num_passes=num_passes,\n",
    "    lr_start=lr_start,\n",
    "    lr_end=lr_end,\n",
    "    show_plots=False\n",
    ")\n",
    "stackview.slice(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Assign pixel SOM clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the pixel SOM using the subsetted data. Training is done using a self-organizing map (SOM).\n",
    "\n",
    "The following data directories/files will be created for pixel clustering:\n",
    "\n",
    "* `pixel_som_weights_name`: file name to store the pixel SOM weights\n",
    "* `pc_chan_avg_som_cluster_name`: file name to store the average channel expression across all pixel SOM clusters\n",
    "* `pc_chan_avg_meta_cluster_name`: same as above for pixel meta clusters\n",
    "* `pixel_meta_cluster_remap_name`: file name to store the SOM cluster to meta cluster manual mappings created using the GUI below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:04:11.371383Z",
     "iopub.status.busy": "2024-11-15T15:04:11.371206Z",
     "iopub.status.idle": "2024-11-15T15:04:11.373588Z",
     "shell.execute_reply": "2024-11-15T15:04:11.373339Z",
     "shell.execute_reply.started": "2024-11-15T15:04:11.371370Z"
    },
    "tags": [
     "pixel_som_path_set"
    ]
   },
   "outputs": [],
   "source": [
    "pixel_som_weights_name = os.path.join(pixel_output_dir, 'pixel_som_weights.feather')\n",
    "pc_chan_avg_som_cluster_name = os.path.join(pixel_output_dir, 'pixel_channel_avg_som_cluster.csv')\n",
    "pc_chan_avg_meta_cluster_name = os.path.join(pixel_output_dir, 'pixel_channel_avg_meta_cluster.csv')\n",
    "pixel_meta_cluster_remap_name = os.path.join(pixel_output_dir, 'pixel_meta_cluster_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each channel is normalized by their 99.9% value across the entire dataset before training. These values get saved to `norm_vals_name`.\n",
    "\n",
    "For a full set of parameters you can customize for `train_pixel_som`, please consult <a href=https://ark-analysis.readthedocs.io/en/latest/_markdown/ark.phenotyping.html#ark.phenotyping.pixel_cluster_utils.train_pixel_som>pixel training docs</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T15:04:27.532212Z",
     "iopub.status.busy": "2024-11-15T15:04:27.532034Z",
     "iopub.status.idle": "2024-11-15T15:06:37.910825Z",
     "shell.execute_reply": "2024-11-15T15:06:37.910349Z",
     "shell.execute_reply.started": "2024-11-15T15:04:27.532199Z"
    },
    "tags": [
     "train_pixel_som"
    ]
   },
   "outputs": [],
   "source": [
    "# create the pixel SOM weights\n",
    "pixel_pysom = pixel_som_clustering.train_pixel_som(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    subset_dir=pixel_subset_dir,\n",
    "    norm_vals_name=norm_vals_name,\n",
    "    som_weights_name=pixel_som_weights_name,\n",
    "    num_passes=1,\n",
    "    seed=42,\n",
    "    overwrite=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the SOM weights learned from `train_pixel_som` to assign pixel clusters to the full preprocessed dataset.\n",
    "\n",
    "Note that each channel is normalized by the respective value stored in `norm_vals_name` (computed in `train_pixel_som`) prior to cluster assignment.\n",
    "\n",
    "`generate_som_avg_files` will compute the average channel expression across all pixel SOM clusters, as well as the number of pixels in each pixel SOM cluster (the data in `pc_chan_avg_som_cluster_name`). This is needed for consensus clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T17:50:33.580134Z",
     "iopub.status.busy": "2024-11-15T17:50:33.579967Z",
     "iopub.status.idle": "2024-11-15T18:08:48.936184Z",
     "shell.execute_reply": "2024-11-15T18:08:48.935826Z",
     "shell.execute_reply.started": "2024-11-15T17:50:33.580123Z"
    },
    "tags": [
     "cluster_pixel_mat"
    ]
   },
   "outputs": [],
   "source": [
    "# use pixel SOM weights to assign pixel clusters\n",
    "pixel_som_clustering.cluster_pixels(\n",
    "    fovs,\n",
    "    base_dir=base_dir,\n",
    "    pixel_pysom=pixel_pysom,\n",
    "    data_dir=pixel_data_dir,\n",
    "    multiprocess=True,\n",
    "    batch_size=batch_size,\n",
    "    overwrite=False\n",
    ")\n",
    "\n",
    "# generate the SOM cluster summary files\n",
    "pixel_som_clustering.generate_som_avg_files(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    pixel_pysom,\n",
    "    data_dir=pixel_data_dir,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    overwrite=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Run pixel consensus clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use consensus hierarchical clustering to cluster pixel SOM clusters into a user-defined number of meta clusters. The consensus clusters are trained on the average channel expression across all pixel SOM clusters (the data stored in `pc_chan_avg_som_cluster_name`). These values are z-scored and capped at the value specified in the `cap` argument prior to consensus clustering. This helps improve meta clustering performance.\n",
    "\n",
    "After consensus clustering, the following are computed by `generate_meta_avg_files`:\n",
    "\n",
    "* The average channel expression across all pixel meta clusters, and the number of pixels per meta cluster (the data in `pc_chan_avg_meta_cluster_name`)\n",
    "* The meta cluster mapping for each pixel SOM cluster in `pc_chan_avg_som_cluster_name` (data is resaved, same data except with an associated meta cluster column)\n",
    "\n",
    "For a full set of parameters you can customize for `pixel_consensus_cluster`, please consult <a href=https://ark-analysis.readthedocs.io/en/latest/_markdown/ark.phenotyping.html#ark.phenotyping.pixel_cluster_utils.pixel_consensus_cluster>pixel consensus clustering docs</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `max_k`: the number of consensus clusters desired\n",
    "* `cap`: used to clip z-scored values prior to consensus clustering (in the range `[-cap, cap]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T22:02:24.661713Z",
     "iopub.status.busy": "2024-11-15T22:02:24.661527Z",
     "iopub.status.idle": "2024-11-15T22:04:55.574968Z",
     "shell.execute_reply": "2024-11-15T22:04:55.574460Z",
     "shell.execute_reply.started": "2024-11-15T22:02:24.661700Z"
    },
    "tags": [
     "pixel_consensus_cluster"
    ]
   },
   "outputs": [],
   "source": [
    "max_k = 10\n",
    "cap = 3\n",
    "\n",
    "# run hierarchical clustering using average pixel SOM cluster expression\n",
    "pixel_cc = pixel_meta_clustering.pixel_consensus_cluster(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    max_k=max_k,\n",
    "    cap=cap,\n",
    "    data_dir=pixel_data_dir,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    multiprocess=True,\n",
    "    overwrite=False,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# generate the meta cluster summary files\n",
    "pixel_meta_clustering.generate_meta_avg_files(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    pixel_cc,\n",
    "    data_dir=pixel_data_dir,\n",
    "    overwrite=False,\n",
    "    pc_chan_avg_som_cluster_name=pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name=pc_chan_avg_meta_cluster_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Interactive adjustments to relabel pixel meta clusters\n",
    "The visualization shows the z-scored average channel expression per pixel SOM and meta cluster. The heatmaps are faceted by pixel SOM clusters on the left and pixel meta clusters on the right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickstart\n",
    "- **Select**: Left Click\n",
    "- **Remap**: **New metacluster** button or Right Click\n",
    "- **Edit Metacluster Name**: Textbox at bottom right of the heatmaps.\n",
    "\n",
    "Selection and remapping details\n",
    "- To select a SOM cluster, click on its respective position in the **selected** bar. Click on it again to deselect.\n",
    "- To select a meta cluster, click on its corresponding color in the **metacluster** bar. Click on it again to deselect.\n",
    "- To remap the selected clusters, click the **New metacluster** button (alternatively, right click anywhere). Note that remapping an entire metacluster deletes it.\n",
    "- To clear the selected SOM/meta clusters, use the **Clear Selection** button.\n",
    "- **After remapping a meta cluster, make sure to deselect the newly created one to prevent unwanted combinations.**\n",
    "\n",
    "Other features and notes\n",
    "- You will likely need to zoom out to see the entire visualization. To toggle Zoom, use Ctrl -/Ctrl + on Windows or ⌘ +/⌘ - on Mac.\n",
    "- The bars at the top show the number of pixels in each SOM cluster.\n",
    "- The text box at the bottom right allows you to rename a particular meta cluster. This can be useful as remapping may cause inconsistent numbering. **You cannot use the same name for different meta clusters; doing so will cause the next step to fail.**\n",
    "- Adjust the z-score limit using the slider on the bottom left to adjust your dynamic range.\n",
    "- When meta clusters are combined or a meta cluster is renamed, the change is immediately saved to `pixel_meta_cluster_remap_name`.\n",
    "- You won't be able to advance in the notebook until you've clicked `New metacluster` or renamed a meta cluster at least once. If you don't want to make changes, just click `New metacluster` to trigger a save before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "rc_file_defaults()\n",
    "plt.ion()\n",
    "\n",
    "pixel_mcd = metaclusterdata_from_files(\n",
    "    os.path.join(base_dir, pc_chan_avg_som_cluster_name),\n",
    "    cluster_type='pixel'\n",
    ")\n",
    "pixel_mcd.output_mapping_filename = os.path.join(base_dir, pixel_meta_cluster_remap_name)\n",
    "pixel_mcg = MetaClusterGui(pixel_mcd, width=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relabel the pixel meta clusters using the mapping, and recompute the meta cluster average files with the new meta cluster names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pixel_apply_remap"
    ]
   },
   "outputs": [],
   "source": [
    "# rename the meta cluster values in the pixel dataset\n",
    "pixel_meta_clustering.apply_pixel_meta_cluster_remapping(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    pixel_data_dir,\n",
    "    pixel_meta_cluster_remap_name,\n",
    "    multiprocess=multiprocess,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# recompute the mean channel expression per meta cluster and apply these new names to the SOM cluster average data\n",
    "pixel_meta_clustering.generate_remap_avg_files(\n",
    "    fovs,\n",
    "    channels,\n",
    "    base_dir,\n",
    "    pixel_data_dir,\n",
    "    pixel_meta_cluster_remap_name,\n",
    "    pc_chan_avg_som_cluster_name,\n",
    "    pc_chan_avg_meta_cluster_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the color scheme returned by the interactive reclustering process. This will be for visualizing the pixel phenotype maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "pixel_cmap_gen"
    ]
   },
   "outputs": [],
   "source": [
    "raw_cmap, _ = colormap_helper.generate_meta_cluster_colormap_dict(\n",
    "    pixel_mcd.output_mapping_filename,\n",
    "    pixel_mcg.im_cl.cmap\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Generate pixel phenotype maps\n",
    "\n",
    "Generate pixel phenotype maps, in which each pixel in the image corresponds to its pixel meta cluster. Select a small subset of your FOVs to view within this notebook. Or if you wish to generate and save a significant amount of FOVs, the masks will be created and saved in batches.\n",
    "\n",
    "Files will be written as `{fov_name}_pixel_mask.tiff` in `pixel_output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "pixel_overlay_fovs"
    ]
   },
   "outputs": [],
   "source": [
    "# select fovs to display\n",
    "subset_pixel_fovs = ['fov0', 'fov1', 'fov2', 'fov3', 'fov4']\n",
    "# , 'fov5', 'fov6', 'fov7', 'fov8', 'fov9', 'fov10', 'fov11', 'fov12', 'fov13', 'fov14', 'fov15', 'fov16', 'fov17', 'fov18', 'fov19', 'fov20', 'fov21','fov22', 'fov23']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pixel_mask_gen_save"
    ]
   },
   "outputs": [],
   "source": [
    "# define the path to the channel file\n",
    "if img_sub_folder is None:\n",
    "    chan_file = os.path.join(\n",
    "        io_utils.list_files(os.path.join(tiff_dir, fovs[0]), substrs=['.tif'])[0]\n",
    "    )\n",
    "else:\n",
    "    chan_file = os.path.join(\n",
    "        img_sub_folder, io_utils.list_files(os.path.join(tiff_dir, fovs[0], img_sub_folder), substrs=['.tif'])[0]\n",
    "    )\n",
    "\n",
    "# generate and save the pixel cluster masks for each fov in subset_pixel_fovs\n",
    "data_utils.generate_and_save_pixel_cluster_masks(\n",
    "    fovs=subset_pixel_fovs,\n",
    "    base_dir=base_dir,\n",
    "    save_dir=os.path.join(base_dir, pixel_output_dir),\n",
    "    tiff_dir=tiff_dir,\n",
    "    chan_file=chan_file,\n",
    "    pixel_data_dir=pixel_data_dir,\n",
    "    cluster_id_to_name_path=os.path.join(base_dir, pixel_meta_cluster_remap_name),\n",
    "    pixel_cluster_col='pixel_meta_cluster',\n",
    "    sub_dir='pixel_masks',\n",
    "    name_suffix='_pixel_mask',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the colored pixel masks for each FOV in `subset_pixel_fovs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "save_pixel_masks"
    ]
   },
   "outputs": [],
   "source": [
    "plot_utils.save_colored_masks(\n",
    "    fovs=subset_pixel_fovs,\n",
    "    mask_dir=os.path.join(base_dir, pixel_output_dir, \"pixel_masks\"),\n",
    "    save_dir=os.path.join(base_dir, pixel_output_dir, \"pixel_mask_colored\"),\n",
    "    cluster_id_to_name_path=os.path.join(base_dir, pixel_meta_cluster_remap_name),\n",
    "    metacluster_colors=raw_cmap,\n",
    "    cluster_type=\"pixel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a subset of the pixel cluster masks that you would like to preview. If the dimensions or text size of the plot need to be adjusted for optimal viewing, change the `figsize` and `dpi` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pixel_overlay_gen"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "for pixel_fov in subset_pixel_fovs:\n",
    "    pixel_cluster_mask = load_utils.load_imgs_from_dir(\n",
    "        data_dir=os.path.join(base_dir, pixel_output_dir, \"pixel_masks\"),\n",
    "        files=[pixel_fov + \"_pixel_mask.tiff\"],\n",
    "        trim_suffix=\"_pixel_mask\",\n",
    "        match_substring=\"_pixel_mask\",\n",
    "        xr_dim_name=\"pixel_mask\",\n",
    "        xr_channel_names=None,\n",
    "    )\n",
    "\n",
    "    plot_utils.plot_pixel_cell_cluster(\n",
    "        pixel_cluster_mask,\n",
    "        [pixel_fov],\n",
    "        os.path.join(base_dir, pixel_meta_cluster_remap_name),\n",
    "        metacluster_colors=raw_cmap,\n",
    "        figsize=(8, 8),\n",
    "        dpi=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Save parameters for use in cell clustering and visual inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are saved:\n",
    "\n",
    "* `fovs`: fovs in `pixel_data_dir`\n",
    "* `channels`: channels used for clustering\n",
    "* `segmentation_dir`: path to the directory containing your segmentated images for each FOV (can be generated using `1_Segment_Image_Data.ipynb`)\n",
    "* `seg_suffix`: suffix plus the file extension of the segmented images for each FOV\n",
    "* `pixel_data_dir`: name of the directory containing the full pixel data with the pixel SOM and meta cluster assignments\n",
    "* `pc_chan_avg_som_cluster_name`: name of the file containing the average channel expression per pixel SOM cluster\n",
    "* `pc_chan_avg_meta_cluster_name`: same as above for pixel meta clusters\n",
    "\n",
    "The file will be saved to `{pixel_cluster_prefix}_cell_clustering_params.json` and will be placed in `pixel_output_dir`. Note that the `pixel_output_dir` you use in `2_Pixie_Cluster_Pixels.ipynb` should be the same as in `3_Pixie_Cluster_Cells.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "cell_param_save"
    ]
   },
   "outputs": [],
   "source": [
    "# define the params dict\n",
    "cell_clustering_params = {\n",
    "    'fovs': io_utils.remove_file_extensions(io_utils.list_files(os.path.join(base_dir, pixel_data_dir), substrs='.feather')),\n",
    "    'channels': channels,\n",
    "    'tiff_dir': tiff_dir,\n",
    "    'img_sub_folder': img_sub_folder,\n",
    "    'segmentation_dir': segmentation_dir,\n",
    "    'seg_suffix': seg_suffix,\n",
    "    'pixel_data_dir': pixel_data_dir,\n",
    "    'pc_chan_avg_som_cluster_name': pc_chan_avg_som_cluster_name,\n",
    "    'pc_chan_avg_meta_cluster_name': pc_chan_avg_meta_cluster_name\n",
    "}\n",
    "\n",
    "# save the params dict\n",
    "with open(os.path.join(base_dir, pixel_output_dir, 'cell_clustering_params.json'), 'w') as fh:\n",
    "    json.dump(cell_clustering_params, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save images for Mantis Viewer\n",
    "\n",
    "Mantis Viewer is a visualization tool for multi-dimensional imaging in pathology. Learn more about Mantis Viewer https://github.com/angelolab/ark-analysis/tree/main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "pixel_mantis_project"
    ]
   },
   "outputs": [],
   "source": [
    "plot_utils.create_mantis_dir(\n",
    "    fovs=subset_pixel_fovs,\n",
    "    mantis_project_path=os.path.join(base_dir, \"mantis\"),\n",
    "    img_data_path=tiff_dir,\n",
    "    mask_output_dir=os.path.join(base_dir, pixel_output_dir, \"pixel_masks\"),\n",
    "    mapping = os.path.join(base_dir, pixel_meta_cluster_remap_name),\n",
    "    seg_dir=pixie_seg_dir,\n",
    "    mask_suffix=\"_pixel_mask\",\n",
    "    seg_suffix_name=seg_suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KINTSUGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "key": "version",
       "op": "remove"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 5,
           "op": "addrange",
           "valuelist": "5"
          },
          {
           "key": 5,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
